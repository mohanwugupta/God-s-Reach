{
  "full_text": "Behavioral/Cognitive\n\n## Credit Assignment in a Motor Decision Making Task Is Influenced by Agency and Not Sensory Prediction Errors\n\n\nX Darius E. Parvin, [1] X Samuel D. McDougle, [3,4] X Jordan A. Taylor, [3,4] and X Richard B. Ivry [1,2]\n\n1Department of Psychology, 2Helen Wills Neuroscience Institute, University of California, Berkeley, California 94720, 3Department of Psychology\nand [4] Princeton Neuroscience Institute, Princeton University, Princeton, New Jersey 08544\n\n\nFailures to obtain reward can occur from errors in action selection or action execution. Recently, we observed marked differences in\nchoice behavior when the failure to obtain a reward was attributed to errors in action execution compared with errors in action selection\n(McDougleetal.,2016). Specifically,participantsappearedtosolvethiscreditassignmentproblembydiscountingoutcomesinwhichthe\nabsence of reward was attributed to errors in action execution. Building on recent evidence indicating relatively direct communication\nbetween the cerebellum and basal ganglia, we hypothesized that cerebellar-dependent sensory prediction errors (SPEs), a signal indicat-\ning execution failure, could attenuate value updating within a basal ganglia-dependent reinforcement learning system. Here we com-\npared the SPE hypothesis to an alternative, \u201ctop-down\u201d hypothesis in which changes in choice behavior reflect participants\u2019 sense of\nagency. In two experiments with male and female human participants, we manipulated the strength of SPEs, along with the participants\u2019\nsense of agency in the second experiment. The results showed that, whereas the strength of SPE had no effect on choice behavior,\nparticipants were much more likely to discount the absence of rewards under conditions in which they believed the reward outcome\ndepended on their ability to produce accurate movements. These results provide strong evidence that SPEs do not directly influence\nreinforcement learning. Instead, a participant\u2019s sense of agency appears to play a significant role in modulating choice behavior when\nunexpected outcomes can arise from errors in action execution.\n\n\nKey words: adaptation; agency; credit assignment; decision making; reinforcement; reward\n\n\nSignificance Statement\n\n\nWhen learning from the outcome of actions, the brain faces a credit assignment problem: Failures of reward can be attributed to\npoor choice selection or poor action execution. Here, we test a specific hypothesis that execution errors are implicitly signaled by\ncerebellar-based sensory prediction errors. We evaluate this hypothesis and compare it with a more \u201ctop-down\u201d hypothesis in\nwhich the modulation of choice behavior from execution errors reflects participants\u2019 sense of agency. We find that sensory\nprediction errors have no significant effect on reinforcement learning. Instead, instructions influencing participants\u2019 belief of\ncausal outcomes appear to be the main factor influencing their choice behavior.\n\n\nIntroduction\n\nConsider the situation in which a tennis player attempts a passing\nshot, only to have her opponent easily return it with a winning\nvolley. The player must decide whether the fault lies with her\n\n\nReceived Dec. 19, 2017; revised March 28, 2018; accepted April 7, 2018.\nAuthor contributions: D. E. P. wrote the first draft of the paper; D. E. P., S. D. M., J. A. T., and R. B. I. edited the paper;\nD. E. P., S. D. M., J. A. T., and R. B. I. designed research; D. E. P. performed research; D. E. P. and S. D. M. analyzed data;\nD. E. P., S. D. M., J. A. T., and R. B. I. wrote the paper.\nThis work was supported by the National Institute of Neurological Disorders and Stroke-National Institute of\nHealth, Grant NS092079 to R. B. I. and Grant NS084948 to J. A. T. We thank Matthew Boggess for help with data\ncollection; and Faisal Mushtaq for helpful discussions.\nThe authors declare no competing financial interests.\nCorrespondenceshouldbeaddressedtoDr. DariusE. Parvin, DepartmentofPsychology, UniversityofCalifornia,\nBerkeleyCA94720E-mail: darius@berkeleyedu\n\n\nchoice to hit a passing shot rather than a lob, or with her poor\nexecution of the passing shot. How the brain solves this credit\nassignment problem, whether to attribute successes or failures to\nthe selection or execution of actions, is poorly understood.\nReinforcement learning models that incorporate variables,\nsuch as reward magnitude and reward probability, have been\nquite successful in predicting choice behavior (Rescorla and\nWagner, 1972) and associated neuronal activity (Schultz et al.,\n1997). Missing from this equation, however, is the role of action\nexecution. These actions introduce a new set of variables to in\ncorporate into the decision-making process, such as the effort\nrequired to make a particular choice (Walton et al., 2006; Hartmann et al., 2013) or the probability of successfully executing the\n\n\ncally overlook the credit assignment problem, given the negligible\nrole of motor errors in standard reinforcement learning tasks.\nWe recently considered how processes specific to action execution could provide information required to solve this problem\n(McDougle et al., 2016). We compared a traditional, buttonpressing \u201cbandit task\u201d with a modified version in which participants indicated their choices by reaching to one of two targets. In\nthe former, the absence of reward provided information about\nthe outcome probabilities associated with each stimulus (e.g.,\naction selection error), whereas in the latter, the absence of reward provided information about reaching inaccuracy (e.g., action execution error), indicated by a visual cursor that landed\noutside the target. The results showed that participants\u2019 choice\nbehavior was less sensitive to action execution errors compared\nwith action selection errors. We proposed that this difference\nmay have been due to the presence of a motor execution error\nsignal in the reaching condition.\nIn the motor domain, sensory prediction errors (SPEs), the\ndiscrepancy between the predicted and actual sensory feedback,\nare used to correct the ongoing movements or to drive motor\nadaptation (Wolpert et al., 1995; Tseng et al., 2007). This signal\ncould be directly exploited by the reinforcement learning system\nto solve the credit assignment problem. That is, the presence of an\nSPE could signal that the absence of the expected outcome (negative reward prediction error [RPE]) should be attributed to an\nerror in movement execution rather than an erroneous choice.\nThis \u201cbottom-up\u201d SPE hypothesis could provide a functional\naccount of the relatively direct connections between the cerebellum, a critical component in the generation of SPEs, and the basal\nganglia, parietal lobe, and orbital prefrontal cortex, core structures in reinforcement learning.\nAlternatively, the credit assignment problem could be solved\nby a more \u201ctop-down\u201d process related to a sense of agency, operationalized here as the belief that success or failure in obtaining\na reward is determined by motor performance rather than the\nresult of a property of the choices themselves. Green et al. (2010)\nproposed a model in which agency influences the rate of change\nin the values associated with response choices. In our reaching\nversion of the bandit task, this would result in behavior consistent\nwith discounting RPEs on trials with negative outcomes.\nThe current study further explores how action execution errors modulate reinforcement learning. The SPE hypothesis predicts that choice behavior should be sensitive to manipulations of\nthe strength of the SPE, even if those manipulations are irrelevant\nto the reward outcomes. In contrast, the agency hypothesis predicts that manipulations of SPE strength should have a minimal\neffect on biases in choice behavior, and instead be influenced by\nthe belief that the outcomes are dependent on their motor accuracy. Using a reaching variant of the two-armed-bandit task, we\nmanipulated SPE by delaying reach feedback (Experiment 1), and\nby using \u201cclamped\u201d reaching feedback (Experiment 2). In Experiment 2, we also manipulated the task instructions to test whether\nbiases in choice behavior were modulated by the participants\u2019\nsense of agency.\n\n\nMaterials and Methods\n\nParticipants. All participants provided written consent, approved by the\ninstitutional review board at the University of California (Berkeley, CA).\nAll participants were right handed, based on self-report and an assessment with the Edinburgh Handedness Inventory (Oldfield, 1971). Participants received either class credit or monetary compensation.\n\n\nWacom, sampling rate = 200 Hz) while holding a digitizing pen, embedded in a custom handle. The stimuli were presented on a monitor that\nwas positioned above the tablet (53.2 cm = 30 cm, ASUS). The monitor\noccludedtheparticipant\u2019sviewoftheirhand. Theexperimentalsoftwarewas\n[custom written in MATLAB (The MathWorks) (RRID: SCR001622) using](https://scicrunch.org/resolver/SCR001622)\n[the Psychophysics toolbox extensions (Pelli, 1997) (RRID: SCR002881).](https://scicrunch.org/resolver/SCR002881)\nReaching task. At the start of each trial, a white circle (diameter 1.2 cm)\nwas presented on the screen, indicating the start position (Fig. 1 A ). The\nparticipant was instructed to move their hand to the start location. Feedback of hand position was indicated by a solid white circle (diameter 0.5\ncm). This feedback was only visible when the hand was within 2 cm of the\nstart position. After the cursor had been held in the start position for 1 s,\ntwo red circles (diameter 1 cm) were presented at a distance of 10 cm, at\n60\u00b0 and 120\u00b0 counter-clockwise relative to the right. The word \u201cGo\u201d\nappeared in the middle of the screen, instructing the participant to reach\nto one of the two circles. The participant was instructed to make a slicing\nmovement, attempting to pass through the selected target. Cursor feedback was removed once the movement was initiated. If the reach amplitude did not reach 10 cm within 1.5 s, the message \u201cPlease Reach Faster\u201d\nwas displayed and the trial was terminated. If the participant\u2019s reach\ndeviated too far from either target (angular error =20\u00b0), the message\n\u201cOut of Bounds\u201d was displayed. In both cases, the trial was immediately\nrepeated.\nIf the hand passed within 20\u00b0 of the target, one of two trial outcomes\noccurred. On rewarded trials, the target color changed to green, a pleasant \u201cding\u201d sound was played, and the number of points earned (1\u2013100)\nwas displayed above the chosen target. On unrewarded trials, the target\nremained red, an unpleasant \u201cbuzz\u201d sound was played, and the number\n\u201c0\u201d was displayed above the chosen target. A box on the top of the screen\nshowed the cumulative total of points earned.\nReward schedule. To assess target choice preference independent of\nreaching accuracy, the reward schedules were predetermined; as such,\nthe outcomes were not contingent on whether or not the reaching movement actually intersected the selected target (with the exception of\nreaches judged to be out of bounds). Hit probability and reward functions were created using a bounded pseudo-sinusoidal function (Fig.\n1 B ). These functions were mirrored for each target, such that the expected value for each target on a given trial was matched. For example, a\n\u201csafe\u201d target with a 90% hit probability and reward value of 10 points\nwould be paired with a matching risky target that had a 10% hit probability and rewarded 90 points. We operationally define risk in terms of\nthe probability of hitting the target. On hit trials, the participant received\nthe associated reward value for that trial; on miss trials, no points were\nawarded. The probability and reward functions were designed so that at\nmultiple points during the experiment, payoffs between the left and right\ntargets gradually shifted, allowing us to track the participant\u2019s choice\npreferences. The same reward schedule was used for all participants, with\nthe position of the targets counterbalanced.\nExperiment 1. Experiment 1 was designed to compare conditions in\nwhich reach errors were signaled by a strong or weak SPE ( n = 20 per\ngroup; total n = 60, 33 female, age range 18\u201325 years). At the location\nwhere the movement amplitude reached 10 cm, the cursor reappeared,\nproviding the participant with a feedback signal that indicated the accuracy of the reach (Fig. 1 C ). Presuming that the participant had intended\nto hit the target, the difference between the center of the target and the\ncursor position indicated the SPE for that trial.\nGiven that the hit/miss outcomes were predetermined, it was necessary to alter the feedback on some of the trials. On trials where the reach\noutcome matched the predetermined outcome, the reach feedback was\nveridical: The feedback cursor would fall on the target on hit trials (22.5%\nof all trials) and off the target on miss trials (27.5% of all trials). On trials\nwhere the reach outcome and predetermined outcome did not match,\nthe reach feedback was manipulated. For \u201chits\u201d that had to be converted\nto \u201cmisses\u201d (25.5% of all trials), the cursor was displayed at a new location away from the target (in the same direction as the side of the target that\nwas hit). To mask the fact that the feedback was sometimes altered, the\ndistribution of the altered feedback signals was designed to closely match\n\n\nFigure 1. Experimental design. A, Trials began with participants moving their hand to place the cursor at the start position. They indicated their choice preference by performing a shooting\nmovement through the selected target. Visual feedback of the hand position was extinguished once the hand left the start position. In Experiment 1, visual feedback of the reach was provided on\nanimaginarycirclewitharadiusequaltothetargetdistance. Onhittrials,thetargetwouldturngreenandapleasant\u201cding\u201dsoundwasgenerated. Onmisstrials,thetargetwouldremainredand\nanunpleasant\u201cbuzz\u201dsoundwasgenerated. Thenumberofpointsearnedwasdisplayedabovethechosentarget(\u201c0\u201dinthecaseofamiss),alongwithacumulativetotalofpointsearneddisplayed\ninabox. B, Top, Rewardfunctions(leftaxis)andhitprobabilities(rightaxis)foreachtarget. Overtrials,thetargetsvaryintermsoftheirrelative\u201crisk\u201d(e.g.,highpayoffbutlowhitprobability)but\narealwaysmatchedintermsoftheexpectedpayoff. Bottom, Threegroupsweretestedwithdifferentfeedbackdelaysandintertrialintervals. ImmediateFeedbackandDelayedTrialsbothreceived\nimmediate reach feedback. Delayed Feedback received the same reach feedback but after a 2 s delay. C, Example feedback for hit and miss trials in Experiment 1. Veridical feedback was provided\nwhenparticipants\u2019actualaccuracy(hitormiss)matchedthepredeterminedoutcome. Fortrialswheretheydidnotmatch,thecursorwouldbebumpedinoroutofthetargetonthesameside,such\nthatparticipantswerenotawareoftheperturbation. D, InExperiment2,feedbackofreachingaccuracywasnotprovided. ForSPE= groups,onmisstrials,thefeedbackcursorwas\u201cclamped\u201dand\nalways presented at the same location between the two targets (regardless of which was chosen). On hit trials, no feedback cursor was presented. For SPE- groups, on all trials, no feedback cursor\nwas presented.\n\n\nFigure 2. Distribution of reach endpoints and feedback location. A, In Experiment 1, reach feedback was minimally altered to match the predetermined reward schedule. B, In Experiment 2,\nclampedfeedbackwasprovidedataninvariantlocation(90\u00b0)onmisstrialsfortheSPE [=] condition. Asaresult,theSPE [=] groupheadinganglesareshiftedawayfromthecenterrelativetotheSPE [=]\n\ngroup, due to implicit adaptation.\n\n\nfrom one side of a normal distribution with a SD of 4.65\u00b0, with the peak\ncentered on the edge of the target. Locations deviating further than 2\ntimesthedistribution\u2019sSD(9.3\u00b0)wereresampled. For\u201cmisses\u201dconvertedto\n\n\noriginal miss. We included the \u201cOut of Bounds\u201d criteria to ensure that the\nfeedback perturbations were relatively small, and thus prevent the participants from becoming aware of the feedback manipulation.\n\n\nprovided. Previous studies have demonstrated that delaying sensory\nfeedback by over 1 s can strongly attenuate the strength of an SPE (Held\net al., 1966; Kitazawa et al., 1995; Honda et al., 2012; Brudner et al., 2016;\nSchween and Hegele, 2017). In the Immediate Feedback group, the cursor reappeared as soon as the reach amplitude exceeded 10 cm (Fig. 1 B ).\nIn the Delayed Feedback group, the cursor feedback was presented after\na 2 s delay. This manipulation confounds feedback delays and the time\nbetween successive trials. To unconfound these factors, we also tested a\nthird group who received immediate cursor feedback but then had to\nwait an additional 2 s before the start of the next trial (Delayed Trials).\nExperiment 2. In Experiment 2, we used a 2 = 2 factorial design ( n = 20\nper group; total n = 80, 51 female, age range 18\u201325 years). The first factor\nwas to test whether an explicit sense of agency would alter participants\u2019\nchoice behavior. The second was to provide a second test of the SPE\nhypothesis.\nIn our previous study, we found no effect of agency (McDougle et al.,\n2016); however, our manipulation, which involved instructing participants that they were either in control or not in control of the hit/miss\noutcomes, may have been complicated by the inclusion of reach feedback\nin the vicinity of the target. The reach feedback may have unintentionally\nswayed participants to believe that they were still in control, regardless of\nthe instructions. Here, we avoided this conflict by removing reach feedback completely. To manipulate a sense of agency, the participants were\ntold that miss trials were either related or not related to their reaching\naccuracy. In the former case, the participants were told that the trial\noutcome reflected whether their reach accurately intersected the chosen\ntarget (Agency [=] ). In the latter case, the participants were told that the\noutcome reflected a probability that a target choice would result in a\npayoff, independent of their reaching accuracy (Agency [=] ). Beyond this\ninstruction, the participants were not informed about the nature of the\nhit probabilities or reward schedule.\nWe also sought a second test of the SPE hypothesis, comparing conditions that did or did not include SPEs on miss trials. For participants in\nthe SPE [=] conditions, we used a variant of task irrelevant clamped feedback (Morehead et al., 2017; Kim et al., 2018) to elicit SPEs without\nconveying reaching performance: On miss trials, the cursor feedback was\nalways presented at a common location positioned between the two targets (90\u00b0) (Fig. 1 D ), appearing as soon as the reach amplitude exceeded\n10 cm. The participants were fully informed that, regardless of which\ntarget was selected, the feedback would always appear straight ahead on\nunrewarded trials. Given the instructions and lack of spatial correlation\nbetween the feedback and reaching movement (Fig. 2 B ), we assumed that\nthese participants would not confuse the clamped feedback as indicative\nof their reach angle. Nonetheless, based on our previous work with\nclamped feedback of this sort, we assumed that these conditions would be\nsufficient to elicit SPE-dependent adaptation and, indeed, confirmed this\nin a separate \u201cClamp-only\u201d control experiment (see \u201cClamp-only\u201d experiment below).\nParticipants in the SPE [=] conditions received clamped feedback on all\nmiss trials. This feedback signal was not presented to participants in the\nSPE [=] conditions. Neither group received cursor feedback on hit trials.\nExperiment 2 block structure. The experiment consisted of 30 baseline\ntrials, 400 decision making trials, and 30 aftereffect trials. The 400 decision making trials had the same reward schedule as Experiment 1. For the\nbaseline and aftereffect trials, only one of the two targets were presented\non each trial (location randomized), and the participant was instructed\nto reach to the target. A \u201cding\u201d indicated that the movement amplitude\nhad exceeded 10 cm. No information was provided concerning reaching\n\naccuracy.\nThe baseline and aftereffect trials were included to assess whether the\nclamped feedback was treated by the motor system as an SPE. If so, the\nheading direction in the aftereffect block should be shifted in the lateral\ndirection compared with the baseline block. Visuomotor adaptation was\noperationalized as a shift in heading angle in the aftereffect trials relative\nto baseline. The heading angle was defined as the angle between the hand\nposition when it crossed the target radius, the start position, and the\ntarget. The heading angle values for the 60\u00b0 target (to the right) were\n\n\ntion to the clamped feedback). All reported aftereffects were baseline\nsubtracted, where the baseline was defined as the mean of all baseline\ntrials.\nClamp-only experiment. The design and logic of Experiment 2 rests on\nthe assumption that the clamped visual feedback is treated as an SPE\n(Morehead et al., 2017; Kim et al., 2018). Although the comparison of the\nbaseline and aftereffect blocks in Experiment 2 provides a test of this\nassumption, we thought it prudent to conduct a clamp-only experiment\nthat used a more traditional sensorimotor adaptation design, one in\nwhich the participants did not have to choose the reach target.\nReaches were made to a single target, displayed at either 60\u00b0 or 120\u00b0,\nthe locations used in Experiments 1 and 2 (see Fig. 4 A ). The experiment\nconsisted of 30 baseline trials (15/target) in which no visual feedback was\nprovided, 120 \u201cclamp\u201d trials (60/target), and 10 aftereffect trials (5/target), again with no visual feedback. The trial structure was the same as in\nthe baseline and aftereffects blocks of Experiment 2.\nThe clamp-only experiment also provided an opportunity to test the\neffect of delayed visual feedback on sensorimotor adaptation, relevant to\nour manipulation in Experiment 1. Two groups were tested (14/group,\n14 female, age range 18\u201325 years), one in which the clamped feedback\nwas provided coincidentally with the reach endpoint (\u201cNo Delay\u201d), and a\nsecond in which the feedback was delayed by 2 s (\u201cDelay\u201d). If the clamp is\ntreated as an SPE, adaptation should be evident in the \u201cNo Delay\u201d group\nand abolished, or severely attenuated in the \u201cDelay\u201d group.\nStatistical analysis. The chosen sample sizes were based on our previous studies using the reaching variant of the two-armed bandit (McDougle et al., 2016) and the clamp method (Morehead et al., 2017; Kim et\nal., 2018). All t tests were two-tailed and used a threshold for significance\n(=) of 0.05 unless stated otherwise. We computed the inverse Bayesfactor ( BF 01) for our results from Experiment 1 to assess the likelihood of\nthe null hypothesis ( H 0) relative to the SPE hypothesis ( H 1). We used a\nmethod proposed by Rouder et al. (2009), using a prior for effect size\nfollowing a Cauchy distribution with a scale factor of 1. Here, BF 01 = 1/3\ncan be considered as strong evidence in favor of the alternative hypothesis, BF 01 = 3 as strong evidence in favor of the null hypothesis, and\nanything between is only considered weak or anecdotal (Dienes, 2014).\n\n\nResults\n\nExperiment 1\nIn Experiment 1, we set out to test the SPE hypothesis, the idea\nthat the operation of the reinforcement learning system is attenuated following trials in which the absence of a reward is attributed to an error in action execution rather than action selection.\nThe core prediction of this bottom-up hypothesis is that the\nstrength of the SPE signal should influence choice behavior. Participants were tested in a two-armed bandit task, indicating their\nchoices on each trial by reaching to one of two targets. In addition\nto receiving reward feedback, cursor feedback indicated the accuracy of the reach. We compared two groups, an Immediate\nFeedback group who saw the feedback cursor immediately at the\nend of the reach; and a Delayed Feedback group, for whom the\nappearance of the feedback cursor was delayed by 2 s. Based on\nprevious studies, the strength, or salience of SPE should be considerably attenuated in the Delayed Feedback group (Held et al.,\n1966; Kitazawa et al., 1995; Honda et al., 2012; Brudner et al.,\n2016; Schween and Hegele, 2017). Given that the 2 s feedback\ndelay also increases the time between successive trials, we also\ntested a Delayed Trials group in which the feedback cursor appeared immediately at the end of the reach, but with an extra 2 s\npause between trials. In this manner, we matched the trial-to-trial\ninterval of the Delayed Feedback and Delayed Trials groups.\nIn standard bandit tasks in which the outcome is not dependentonactionexecution,peopletypicallyshowapreferenceforthe\n\u201csafe\u201d target, consistent with a risk aversion bias (Kahneman and\n\n\nFigure3. Increasingthetrial-to-trialinterval,eitherbydelayingfeedbackorincreasingtheintertrialintervalresultedinaweakerpreferencefortheriskytarget. A, Meangroupchoicebehavior\nreveals overall preference for riskier target throughout the experiment. Colored lines indicate the proportion of choices made to the riskier target, averaged over participants in each condition\n(calculatedovera19-trialwindowmovingaverage). Therelative\u201criskiness\u201doftarget1andtarget2(determinedbythepredefinedrewardschedule)areshownforillustrativepurposes(blacksolid\nanddashedlines). B, Riskpreferencequantifiedastheratiooftrialswheretheriskiertargetwaschosenoverthetotalnumberoftrials. Allgroupsexhibitedapreferencefortheriskierchoice(=0.50),\nwiththiseffectsignificantlygreaterfortheIFgroupcomparedwiththeothertwo. IF, ImmediateFeedback; DF, DelayedFeedback; DT, DelayedTrials. Errorbarsindicate =1SEMoverparticipants.\n\n\na striking reversal of this preference when the choices were indicated\nby reaches, so that the failure to obtain a reward was attributed to a\nfailure of action execution. The SPE hypothesis predicts that this\nreversal is due to the presence of SPEs on miss trials. Consistent with\nthose results, the Immediate Feedback group and Delayed Trials\ngroup showed a consistent preference for the riskier target over the\ncourse of the experiment (Fig. 3 A ). However, in contrast to the SPE\nhypothesis,theDelayedFeedbackgroupalsoshowedareversalofthe\nrisk aversion bias, even though we assume the strength of the SPE is\ngreatly attenuated by the delay (an assumption we confirm in\nClamp-only Experiment).\nFor each trial, we defined the risky target as the one with the\nlower hit probability, but higher payoff and, as such, the option\nwith a larger variance of potential outcomes (Kahneman and\nTversky, 1979; Caraco et al., 1980; Dayan and Niv, 2008; Schultz,\n2016). Using this definition, we quantified participants\u2019 choice\nbiases by calculating the ratio of trials in which they picked the\nriskier target over the total number of trials (excluding the few\nout of bounds trials). A one-way ANOVA revealed a significant\neffect of group on risk bias ( F (2,57) = 4.65, p = 0.01; Fig. 3 B ).\nPost hoc t tests using Bonferroni-adjusted = levels of 0.017\n(.05/3) were conducted. A numerical but nonsignificant difference (after correcting for multiple comparisons) existed between\nthe Immediate Feedback and Delayed Feedback groups ( t (38) =\n2.13, p = 0.04). This difference is in a direction consistent with\nthe hypothesis that SPE influences choice behavior. However, we\nobserved a significant difference between the Immediate Feedback and Delayed Trials groups ( t (38) = 2.95, p = 0.005), indicating that an increase in intertrial interval alone (i.e., without\nmanipulating the SPE) affected choice preference. The Delayed\nFeedback group had a numerically lower risk bias compared with\nthe Delayed Trials group, opposite to what the SPE hypothesis predicts, although this difference was nonsignificant ( t (38) = 0.93, p =\n0.36). An inverse Bayes factor comparing the odds of the hypothesis\nthat the Delayed Feedback and Delayed Trials risk biases were equal\n(null) versus the hypothesis that they were unequal provided only\nweak support in favor of the null ( BF 01 = 2.95).\nTogether, these results fail to support the hypothesis that\nchoice biases are modulated by the strength of the SPE. The most\nparsimonious interpretation of the current results is that choice\nbiases in the current task decay as a function of the time between\nsuccessive trials, independent of the strength of the SPE. This\n\n\nmemory that could be used to adjust the next movement (see\nDiscussion).\n\n\nExperiment 2\nThe results of the first experiment indicate that SPE is not a\ncritical signal that directly modulates choice biases. An alternative hypothesis is that, due to the sense of agency associated with\nreaching (Green et al., 2010), people may be slow to update their\nestimates of action execution errors based on recent outcomes.\nFor example, the participants have a strong prior for their reaching competency and believe that their execution errors simply\nreflect motor noise, a variable that should operate randomly\nacross trials. We set out to test this hypothesis in Experiment 2,\ncomparing conditions in which participants were told that the\nabsence of reward was attributed to a failure in motor execution\n(Agency [=] ) to conditions in which the absence of reward was\nattributed to a property of the object (Agency [=] ). If the sense of\nagency is critical, we would expect participants to prefer the\n\u201csafe\u201d target in the latter conditions.\nWe also designed Experiment 2 to provide a second test of the\nSPE hypothesis. To that end, we compared conditions in which\nthe trial outcome included clamped cursor feedback (SPE [=] ) or\ndid not include this feedback (SPE [=] ). This feedback, when provided, was always presented at the same location midway between\nthe two targets, independent of their target choice. Based on previous work with clamped feedback (Morehead et al., 2017; Kim et\nal., 2018), we assumed that this signal would automatically be\ntreated by the motor system as an SPE, driving sensorimotor\nadaptation. However, given the results of Experiment 1, we expected that the presence or absence of SPE would not influence\nchoice behavior.\nWe first verified that clamped feedback, even if only presented\nat the end of the movement, was sufficient to produce adaptation\n(see Materials and Methods, Clamp-Only Experiment). Despite\nbeing informed about the nature of the clamped feedback and\ninstructed to ignore it, robust adaptation was observed when the\nclamped feedback was presented: During the clamp block, the\nheading angle for each target shifted in the opposite direction of\nthe cursor and an aftereffect was observed (Fig. 4 B ). A t test of the\nbaseline-subtracted final heading angle revealed the aftereffect\nbeing significantly =0 ( t (13) = 4.65, p = 0.001). Moreover, these\neffects were absent if the feedback was delayed by 2 s ( t (13) =\n\n\nFigure 4. Clamp-only experiment showing sensorimotor adaptation from clamped feedback, but only if the feedback is immediate. A, Participants were instructed to reach toward the single\ntarget. Clampedfeedbackwouldalwaysappearstraightaheadattheendofthereach,regardlessoftheparticipant\u2019sheadingangle. B, Immediateclampedfeedback(\u201cNoDelay\u201d)elicitsasignificant\naftereffectintheexpecteddirectionforbothtargets. Noaftereffectisobservedwhentheclampedfeedbackisdelayedby2s(\u201c2sDelay\u201d). Linesrepresentmeanheadingangleoverparticipantsand\nshaded regions around the lines represent =1 SEM over participants. Gray regions represent baseline and aftereffect trials with no feedback.\n\n\nFigure5. Senseofagency,butnotpresenceofSPE,influenceschoicepreference. A, Headingangleofreachesrevealsthetimecourseofadaptation. Headingangleforthe60\u00b0targetareflipped\nsuchthatpositiveisinthedirectionofadaptation. Linesindicatemeanheadingangleoverparticipants. Shadedregionsaroundthelinesrepresent =1SEMoverparticipants. Grayregionsrepresent\nbaselineandaftereffecttrialswhereonlyonetargetwaspresentedandnoreachfeedbackwasprovided. B, Baseline-subtractedaftereffectsshowsignificantadaptationforbothSPE [=] conditions,\nandnonefortheSPE [=] conditions. C, GroupaveragedchoicebehaviorshowsabiastowardthesafetargetfortheAgency [=] conditions,andnobiasforAgency [=] conditions. Coloredlinesindicate\ntheproportionofchoicesmadetotheriskiertarget,averagedoverparticipantsineachcondition(calculatedovera19-trialwindowmovingaverage). Therelative\u201criskiness\u201doftarget1andtarget\n2 (determined by the predefined reward schedule) are shown for illustrative purposes (black solid and dashed lines). D, Risk preference quantified as the ratio of trials where the riskier target was\nchosen over the total number of trials. Choice bias is influenced by a sense of agency, rather than SPE.\n\n\nrobust implicit learning (Held et al., 1966; Kitazawa et al., 1995;\nHonda et al., 2012; Brudner et al., 2016; Schween and Hegele,\n2017).\nAdaptation also occurred in response to the clamped feedback\nin the main experiment. During the choice trials, heading angle\nagain shifted in the opposite direction of the cursor (Fig. 5 A ), and\nthere was a pronounced aftereffect (Fig. 5 B ). (Such an accumulation of adaptation leading to an aftereffect would not occur\nin Experiment 1, as errors were presented on both sides for\neach target). These effects were not observed for the groups in\nwhich the cursor was never presented (SPE-groups). A two-way\nANOVA comparing the heading angle in the aftereffect block to\nthe baseline block revealed a main effect of SPE ( F (1,76) = 40.7, p =\n0.001), but no effect of agency ( F (1,76) = 1.05, p = 0.31) or an interaction ( F (1,76) = 0.38, p = 0.54). We note that the magnitude of\n\n\nindicate that adaptation is influenced by a sense of agency, the\nparticipants in the Agency [=] group chose the risky target more\noften (see below), experienced more \u201cmiss trials,\u201d and thus received more SPEs.\nHaving established that the clamped feedback was an effective\nSPE, we next asked whether choice behavior was influenced by\nthe presence of an SPE, a sense of agency, or an interaction of\nthese variables. When participants were led to believe that the\nabsence of reward was due to an action execution error, they did\nnot show the same risk averse (\u201csafe\u201d) bias compared with when\nthey were told that the absence of reward reflected a probabilistic\nproperty of the target. As can be seen in Figure 5 C, D, the\nAgency [=] groups tracked the \u201csafe\u201d target, whereas the Agency [=]\n\ngroups showed no consistent bias in their choice behavior. In\ncontrast, the presence of an SPE had no influence on choice be\n\nFigure6. AgencymodelfitsforExperiment2. A, Simulationsbasedonfittedparametersproducepatternofriskbiasesthataresimilar\ntothoseobservedinthefourconditionsofExperiment2. B, Fittedlearningparameters(=payoff and =prob)foreachcondition. Agency [=]\n\nconditions have a lower =prob than Agency [=] conditions, consistent with the hypothesis that participants treat hit probabilities as less\ntemporallydependentwhentheyhaveasenseofagency. Errorbarsindicate =1SEMoverparticipants.\n\n\np = 0.78), and there was no interaction between these variables\n( F (1,76) = 0.03, p = 0.87).\nIn summary, the results of Experiment 2 indicate that the\npresence of SPE, although leading to adaptation, was not sufficient to influence decision making. In contrast, variation in the\nsense of agency did influence choice behavior, with participants\nmore likely to choose the risky target when they believed they\nwere in control, at least to some degree, of the trial outcome.\n\n\nModel-based analysis of the agency hypothesis\nExperiment 2 was designed to examine whether choice behavior\nis affected when a sense of agency is explicitly manipulated, operationalized as the belief that outcomes are the result of motor\nperformance. We hypothesized that a sense of agency would influence behavior by reducing the influence of temporal dependency of trial outcomes (Green et al., 2010). Specifically, if motor\nerrors are assumed to reflect random noise in the Agency [=] conditions, recent hits and misses would not be informative about\nfuture hits and misses. In contrast, hit and miss outcomes are\nindependent of the agent\u2019s motor accuracy in the Agency [=] conditions; thus, recent outcomes should provide useful information\nabout future outcomes.\nToevaluatewhetherthisagencyhypothesiscouldaccountforour\nobserved behavior in Experiment 2, we developed a reinforcement\nlearning model to capture how temporal dependency could influence choice behavior. In this model, the estimated hit probabilities\np\u02c6 t( x ) and payoffs E t( x ) for each target x on trial t are updated on a\ntrial-by-trial basis, based on the differences between the actual and\npredictedoutcomes(McDougleetal.,2016). Thedegreeoftemporal\ndependence is captured by two learning rate parameters, =prob and\n=payoff, that correspond to the proportion that these estimates are\nupdated based on the previous trial outcome as follows:\n\n\n= prob, t = rt = p\u02c6t = x =\n\n\n= payoff, t = rt = Et = x =\n\n\np\u02c6t =1= x = = p\u02c6t = x = == prob = prob, t\n# Et =1= x = = = EEt = t = xx ==, == payoff = payoff, t, if missif hitt t\n\n\nwhere p\u02c6 t( x ) takes on a value between 0 and\n1 for each target, representing the probability that a reach to that target will result\nin a hit. The hit or miss outcome (independent of reward), r , is coded as a 1 or 0\nfor a hit or a miss, respectively. Differences between the estimated hit probability and the actual outcome =prob,t, are\nmultiplied by =payoff and added to the estimated hit probability for the next trial.\nAs a result, =prob captures the degree to\nwhich a participant updates the estimates\nof hit probability as a result of previous\ntrials. By fitting =prob as a free parameter\nfor each participant, we can estimate the\ndegree to which they behaved as though\nthey believed the hit outcomes were tem\n)foreachcondition. Agency [=]\n\nporally dependent, with higher values\nrepresenting stronger temporal dependence. If participants treat motor execution errors as temporally independent\nwhen they believe the outcomes are dependent on their reaching accuracy (Agency [=] groups), we\nshould observe lower =prob compared with when they believe the\noutcomes are not dependent on reaching accuracy (Agency [=]\n\ngroups).\nEstimated payoffs were updated in a similar manner to estimated probabilities. However, for payoffs, r takes on values from\n1 to 100 according to the observed payoff, and the update only\noccurs following hit trials. This conditional is a central component of the model, as it effectively separates trials in which outcomes are due to motor errors from trials that result in standard\nRPEs. =payoff is fit as a free parameter for each participant and also\nreflects the degree of temporal dependence in payoffs. Because\nthe payoff amounts were not dependent on hit accuracy, but\nrather a property of the target, we expected =payoff to be approximately constant across all the experimental conditions.\nEstimated target values V ( x ) were transformed into probabilities using a standard softmax function. The inverse temperature\nparameter (=) for the softmax was fit with one common value\nfor all 80 participants in Experiment 2, resulting in 161 free\nparameters in total (one =prob and =payoff per participant, and\none common =). Free parameter estimates were made using\nthe fmincon function in MATLAB, which minimized the negative log likelihood of the choices for the parameters. The\nlearning rates (=prob and =payoff) were bounded between 0 and\n1, and the inverse temperature parameter (=) was bounded\nbetween 0.05 and 10.\nWe fit the learning parameters, then generated choice data to\nsimulate risk preferences. The agency model was capable of simulating the pattern of behavioral risk biases observed in Experiment 2 (Fig. 6 A ). Consistent with the predictions of the agency\nhypothesis, the groups that were told their reaching accuracy did\nnot influence hit probability (Agency [=] groups) had a higher\n=probability value than the groups that were told their reaching\naccuracy determined the hit outcomes (Agency [=] groups) (Fig.\n6 B ). A two-way ANOVA revealed a significant effect of agency on\n=prob ( F (1,76) = 7.85, p = 0.01), no effect of SPE ( F (1,76) = 1.82,\np = 0.18), and no interaction between the two ( F (1,76) = 0.08, p =\n0.78). Also consistent with the agency hypothesis, a two-way\nANOVArevealednosignificanteffectsofagencyon =payoff ( F (1,76) =\n\n\nThese results support the hypothesis that differences in\nchoice behavior across groups were mainly influenced by the\ndegree to which they treated hit probabilities as being temporally dependent, with a belief of agency leading to more temporal independence.\n\n\nDiscussion\n\nPeople are less sensitive to unrewarded outcomes when they are\nattributed to errors in action execution rather than action selection (McDougle et al., 2016). The main objective of this study was\nto evaluate different cues that could be used to solve this credit\nassignment problem. In earlier work, we had proposed a bottom-up\nhypothesis by which cerebellar-dependent SPEs were exploited\nby the reinforcement learning system, signaling the presence of\nan execution error (McDougle et al., 2016). By this model, SPEs\nprovide a salient signal that the trial outcome should be attributed to the agent (i.e., execution error), rather than the chosen\nobject (i.e., selection error). We tested this hypothesis in Experiment 1 by manipulating the strength of SPE and in Experiment 2\nby presenting movement-irrelevant SPEs. In both cases, the results failed to support the hypothesis that SPE played a critical\nrole in producing the observed bias in choice behavior. Instead,\nwe found that the sense of agency had a significant effect on\nchoice behavior, suggesting that the credit assignment problem\nmay be solved in a more indirect, top-down manner.\n\n\nSalience of SPEs does not influence biases in choice behavior\nThe strongest argument against the SPE hypothesis comes from\nExperiment 1. Here we compared conditions in which the feedback cursor was presented immediately at the end of the movement or after a 2 s delay. Previous work, as well as our clamp-only\ncontrol experiment, has shown that a 2 s feedback delay strongly\nattenuates sensorimotor adaptation (Held et al., 1966; Kitazawa\net al., 1995; Honda et al., 2012; Brudner et al., 2016; Schween and\nHegele, 2017), presumably because the delay weakens the SPE. If\nSPE directly modulates choice preferences, then we expect participants to become more sensitive to unrewarded outcomes\nwhen the feedback was delayed. Although this effect was observed, a similar pattern was elicited when the intertrial interval\nwas extended by 2 s, even if the cursor feedback was immediate.\nThus, the most parsimonious account of these results is that the\ntime between successive choices, rather than SPE, decreased sensitivity to unrewarded outcomes.\nWhy might an increase in the intertrial interval change choice\npreferences? One hypothesis is that some form of iconic motor\nmemory is strong when the interval is short (Adams and Dijkstra,\n1966; Posner and Konick, 1966; Laabs, 1973; Annett, 1995; Miyamoto et al., 2014), leading the participants to believe they can\ncorrect the execution error. However, we found no evidence that\nparticipants showed a stronger adjustment in reach trajectories in\nthe Immediate Feedback condition compared with when the\nfeedback or intertrial interval was extended: The mean proportion of the error corrected on trials where feedback was artificially\nperturbed was 0.57 (SE = 0.04) for the Immediate Feedback\ncondition, 0.57 (0.08) for the Delayed Feedback condition, and\n0.53 (0.04) for the Delayed Trials conditions. A one-way ANOVA\non the regression between error and change in heading angle\nrevealed no effect of group ( F (2,57) = 0.12, p = 0.89). An alternative hypothesis is that the longer intertrial interval resulted in\nmore time discounting of the potential rewards for each target\n\n\nThe results of Experiment 2 provide further evidence against\nthe SPE hypothesis. Here we used a method in which the SPE\nsignal is not contingent on movement accuracy. Consistent with\nour previous work, this method was sufficient to produce adaptation in the reaching behavior of the participants. Nonetheless,\nchoice biases were similar, regardless of whether this signal was\npresent. Together, the results argue against a simple, bottom-up\nmodel in which an SPE signal is sufficient to attenuate value\nupdates when the outcome error is attributed to a failure in motor execution.\n\n\nChoice biases are influenced by a sense of agency\nThe results of the present study point toward a more top-down\nmechanism for solving the credit assignment required to differentiate execution and selection errors. This was most clearly\nobserved in the results of Experiment 2, where sensitivity to\nunrewarded outcomes was reduced when the instructions emphasized that the participants had some degree of agency in determining the outcome, with agency operationalized as the belief\nthat outcomes are dependent on one\u2019s motor performance. Similarly, Green et al. (2010) found that choice behavior could be\ndramatically altered by instructing participants that the trial outcome was either determined by the computer or contingent on\nmovement execution. Computationally, they suggested that people assume weaker temporal dependence between successive\nevents when the outcomes depend on motor output, given that\nerrors from motor noise are assumed to be random. Properties of\nthe object, however, may be more temporally dependent (e.g., the\ntarget with the high payoff on the previous trial is likely to yield a\nhigh payoff on the next trial).\nIn modeling the data from Experiment 2, we adopted an operational definition of agency introduced by Green et al. (2010),\nnamely, that a sense of agency will cause choices to be more\ntemporally independent. Consistent with the agency hypothesis,\nthe fits showed that participants in conditions of high agency\nwere less likely to behave as though hit outcomes were temporally\ndependent. In other words, by treating execution errors as\nthough they were random events and unlikely to occur again,\nthey were more likely to choose the target with the higher expected payoff. Participants in the low agency condition, however,\nwere more likely to behave as though misses were a property of\nthe target and, therefore, were biased to avoid the target which\nresulted in more misses.\nWe note that, in our earlier study (McDougle et al., 2016), we\nhad included a similar manipulation of a sense of control, informing participants that the position of the feedback cursor was\neither dependent or independent of their movement. Contrary to\nthe current results, we observed no effect of agency on choice\nbehavior when an SPE-like signal was present. However, the feedback cursor still appeared near the selected target, either as veridical feedback or in a slightly shifted position. It is possible that,\ndespite the instructions, the correlation between their movements and sensory feedback may have led the participants to\nbelieve, implicitly or explicitly, that they could control the reward\noutcomes. The clamped feedback used in Experiment 2 avoids\nthis problem because the feedback was spatially independent of\nthe movement.\nA similar explanation may also account for the betweenexperiment differences in choice behavior observed in conditions\nin which the participants were instructed to believe they were in\ncontrol of the trial outcomes. Although the reward schedules\n\n\nThis was verified in a post hoc analysis, restricted to the Immediate\nFeedback condition in Experiment 1 and the two Agency [=]\n\ngroups in Experiment 2 ( t (58) = 4.25, p = 0.001). The main difference between these conditions was that endpoint reach feedback was provided in Experiment 1, but not Experiment 2. The\nendpoint feedback not only provided a salient cue for motor\nperformance, but also signaled a strong causal relationship association between trials in which the cursor hit the target and the\nparticipant being awarded points. These signals would likely increase the participants\u2019 confidence that the outcomes reflect their\nmotor performance, increasing their sense of agency and, thus,\nproduce a stronger risk bias.\nIn addition to an overall sense of agency, there is another way\nin which reach feedback might influence choice behavior. The\npresence of reach feedback results in salient, \u201cnear miss\u201d trials.\nThese have been shown, at least under some conditions, to produce similar hemodynamic responses as are observed with rewarded trials (Clark et al., 2009). Treating these near miss\noutcomes as rewarding, even if only slightly, would result in a\nstronger risk bias when reach feedback was present in Experiment\n1, but not in Experiment 2.\n\n\nMechanistic considerations for the modulation of\nreinforcement learning by execution errors\nAs noted in the Introduction, distinguishing between action execution and action selection errors is important to optimize\nchoice behavior. Knocking over a cup of coffee should not make\nus dislike coffee, even though we failed to obtain an expected\nreward. Current models of decision making tend to be based on\ntasks in which execution errors are absent; yet these systems\nevolved in organisms in which outcomes almost always reflected\nthe interaction of processes involved in selection and execution.\nWe can envision two ways in which an execution error might gate\nvalue updating. The negative RPE signals associated with unsuccessful outcomes might be attenuated. Or the operation by which\nthese signals modify value representations might be disrupted.\nThe SPE hypothesis was motivated, in part, by consideration\nof recently described projections between the cerebellum and\nbasal ganglia (Hoshi et al., 2005; Bostan et al., 2010; Chen et al.,\n2014) and association areas of the cerebral cortex implicated in\nvalue representation (O\u2019Doherty, 2004; Choi et al., 2012). We\nhypothesized that execution error signals, which evolved to keep\nthe sensorimotor system calibrated, may have come to be exploited by the reinforcement learning system. However, the results from the current experiments provide strong evidence\nagainst this simple, bottom-up account of how a decision-making\nsystemmightdistinguishbetweenactionexecutionandactionselection errors.\nInstead, the current results suggest that this gating process is\ndriven by explicit knowledge about the source of errors, information that is dependent on a sense of agency. This contextual\nknowledge could have a direct influence on how RPEs are computed or used to update value representations. The recruitment\nof working memory (Collins et al., 2017) and explicit knowledge\nabout task contingencies (Li et al., 2011) have been shown to\naffect hemodynamic signatures of RPEs in ventral striatum and\nventromedial prefrontal cortex. In a similar fashion, top-down\nknowledge about the success or failure of action execution could\nprovide a similar modulatory signal, either to a system generating\nRPEs or using this information to update value representations.\n\n\nsensitive to the intersection of action execution and action\n\nselection.\n\n\nReferences\nAdams JA, Dijkstra S (1966) Short-term memory for motor responses. J Exp\n[Psychol 71:314\u2013318. CrossRef Medline](http://dx.doi.org/10.1037/h0022846)\nAnnett J (1995) Motor imagery: perception or action? Neuropsychologia\n[33:1395\u20131417. CrossRef Medline](http://dx.doi.org/10.1016/0028-3932(95)00072-B)\nBostan AC, Dum RP, Strick PL (2010) The basal ganglia communicate with\n[the cerebellum. Proc Natl Acad Sci U S A 107:8452\u20138456. CrossRef](http://dx.doi.org/10.1073/pnas.1000496107)\n\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/20404184)\nBrudner SN, Kethidi N, Graeupner D, Ivry RB, Taylor JA (2016) Delayed\nfeedback during sensorimotor learning selectively disrupts adaptation but\n[not strategy use. J Neurophysiol 115:1499\u20131511. CrossRef Medline](http://dx.doi.org/10.1152/jn.00066.2015)\nCaraco T, Martindale S, Whittam TS (1980) An empirical demonstration of\n[risk-sensitive foraging preferences. Anim Behav 28:820\u2013830. CrossRef](http://dx.doi.org/10.1016/S0003-3472(80)80142-4)\nChen CH, Fremont R, Arteaga-Bracho EE, Khodakhah K (2014) Short latency cerebellar modulation of the basal ganglia. Nat Neurosci 17:1767\u2013\n[1775. CrossRef Medline](http://dx.doi.org/10.1038/nn.3868)\nChoi EY, Yeo BT, Buckner RL (2012) The organization of the human striatum estimated by intrinsic functional connectivity. J Neurophysiol 108:\n[2242\u20132263. CrossRef Medline](http://dx.doi.org/10.1152/jn.00270.2012)\nClark L, Lawrence AJ, Astley-Jones F, Gray N (2009) Gambling near-misses\nenhance motivation to gamble and recruit win-related brain circuitry.\n[Neuron 61:481\u2013490. CrossRef Medline](http://dx.doi.org/10.1016/j.neuron.2008.12.031)\nCollins AG, Ciullo B, Frank MJ, Badre D (2017) Working memory load\n[strengthens reward prediction errors. J Neurosci 37:4332\u20134342. CrossRef](http://dx.doi.org/10.1523/JNEUROSCI.2700-16.2017)\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/28320846)\nDayan P, Niv Y (2008) Reinforcement learning: the good, the bad and the\n[ugly. Curr Opin Neurobiol 18:185\u2013196. CrossRef Medline](http://dx.doi.org/10.1016/j.conb.2008.08.003)\nDienes Z (2014) Using Bayes to get the most out of non-significant results.\n[Front Psychol 5:781. CrossRef Medline](http://dx.doi.org/10.3389/fpsyg.2014.00781)\nFrederick S, Loewenstein G, O\u2019Donoghue T (2002) Time discounting and\n[time preference: a critical review. J Econ Lit 40:351\u2013401. CrossRef](http://dx.doi.org/10.1257/jel.40.2.351)\nGreen CS, Benson C, Kersten D, Schrater P (2010) Alterations in choice\nbehavior by manipulations of world model. Proc Natl Acad Sci U S A\n[107:16401\u201316406. CrossRef Medline](http://dx.doi.org/10.1073/pnas.1001709107)\nHartmann MN, Hager OM, Tobler PN, Kaiser S (2013) Parabolic discounting of monetary rewards by physical effort. Behav Processes 100:192\u2013196.\n[CrossRef Medline](http://dx.doi.org/10.1016/j.beproc.2013.09.014)\nHeld R, Efstathiou A, Greene M (1966) Adaptation to displaced and delayed\nvisual feedback from the hand. J Exp Psychol 72:887\u2013891.\nHonda T, Hirashima M, Nozaki D (2012) Habituation to feedback delay\nrestores degraded visuomotor adaptation by altering both sensory prediction error and the sensitivity of adaptation to the error. Front Psychol\n[3:540. CrossRef Medline](http://dx.doi.org/10.3389/fpsyg.2012.00540)\nHoshi E, Tremblay L, Fe\u00b4ger J, Carras PL, Strick PL (2005) The cerebellum\n[communicates with the basal ganglia. Nat Neurosci 8:1491\u20131493. CrossRef](http://dx.doi.org/10.1038/nn1544)\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/16205719)\nKahneman D, Tversky A (1979) Prospect theory: an analysis of decision\n[under risk. Econometrica 47:263\u2013291. CrossRef](http://dx.doi.org/10.2307/1914185)\nKim HE, Morehead JR, Parvin DE, Moazzezi R, Ivry RB (2018) Invariant\nerrors reveal limitations in motor correction rather than constraints on\n[error sensitivity. Commun Biol 1:19. CrossRef](http://dx.doi.org/10.1038/s42003-018-0021-y)\nKitazawa S, Kohno T, Uka T (1995) Effects of delayed visual information on\nthe rate and amount of prism adaptation in the human. J Neurosci 15:\n[7644\u20137652. CrossRef Medline](http://dx.doi.org/10.1523/JNEUROSCI.15-11-07644.1995)\nLaabs GJ (1973) Retention characteristics of different reproduction cues in\n[motor short-term memory. J Exp Psychol 100:168\u2013177. CrossRef](http://dx.doi.org/10.1037/h0035502)\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/4744492)\nLandy MS, Trommersha\u00a8user J, Daw ND (2012) Dynamic estimation of\ntask-relevant variance in movement under risk. J Neurosci 32:12702\u2013\n[12711. CrossRef Medline](http://dx.doi.org/10.1523/JNEUROSCI.6160-11.2012)\nLi J, Delgado MR, Phelps EA (2011) How instructed knowledge modulates\nthe neural systems of reward learning. Proc Natl Acad Sci U S A 108:55\u2013\n[60. CrossRef Medline](http://dx.doi.org/10.1073/pnas.1014938108)\nMcDougle SD, Boggess MJ, Crossley MJ, Parvin D, Ivry RB, Taylor JA (2016)\nCredit assignment in movement-dependent reinforcement learning. Proc\n[Natl Acad Sci U S A 113:6797\u20136802. CrossRef Medline](http://dx.doi.org/10.1073/pnas.1523669113)\nMiyamoto YR, Wang SX, Brennan AE, Smith MA (2014) Distinct forms of\n\n\ntional and Computational Motor Control, Washington DC, District of\nColumbia.\n\nMorehead JR, Taylor JA, Parvin DE, Ivry RB (2017) Characteristics of implicit sensorimotor adaptation revealed by task-irrelevant clamped feed[back. J Cogn Neurosci 29:1061\u20131074. CrossRef Medline](http://dx.doi.org/10.1162/jocna01108)\nNiv Y, Edlund JA, Dayan P, O\u2019Doherty JP (2012) Neural prediction errors\nreveal a risk-sensitive reinforcement-learning process in the human\n[brain. J Neurosci 32:551\u2013562. CrossRef Medline](http://dx.doi.org/10.1523/JNEUROSCI.5498-10.2012)\nO\u2019Doherty JP (2004) Reward representations and reward-related learning\nin the human brain: insights from neuroimaging. Curr Opin Neurobiol\n[14:769\u2013776. CrossRef Medline](http://dx.doi.org/10.1016/j.conb.2004.10.016)\n\nOldfield RC (1971) The assessment and analysis of handedness: the Edin[burgh Inventory. Neuropsychologia 9:97\u2013113. CrossRef Medline](http://dx.doi.org/10.1016/0028-3932(71)90067-4)\nPelli DG (1997) The VideoToolbox software for visual psychophysics:\n[transforming numbers into movies. Spat Vis 10:437\u2013442. CrossRef](http://dx.doi.org/10.1163/156856897X00366)\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/9176953)\n\nPosner MI, Konick AF (1966) Short-term retention of visual and kinesthetic\n[information. Organ Behav Hum Perform 1:71\u201386. CrossRef](http://dx.doi.org/10.1016/0030-5073(66)90006-7)\nRescorla RA, Wagner AR (1972) A theory of Pavlovian conditioning: variations in the effectiveness of reinforcement and nonreinforcement. In:\n\nClassical conditioning, Vol II: Current research and theory (Black AH,\nProkasy WF, eds), pp 64\u201399. New York, NY: Appleton-Century-Crofts.\nRouder JN, Speckman PL, Sun D, Morey RD, Iverson G (2009) Bayesian t\ntests for accepting and rejecting the null hypothesis. Psychon Bull Rev\n[16:225\u2013237. CrossRef Medline](http://dx.doi.org/10.3758/PBR.16.2.225)\n\n\nSchultz W (2016) Dopamine reward prediction error coding. Dialogues\n[Clin Neurosci 18:23\u201332. Medline](http://www.ncbi.nlm.nih.gov/pubmed/27069377)\nSchultz W, Dayan P, Montague PR (1997) A neural substrate of prediction\n[and reward. Science 275:1593\u20131599. CrossRef Medline](http://dx.doi.org/10.1126/science.275.5306.1593)\nSchween R, Hegele M (2017) Feedback delay attenuates implicit but facilitates explicit adjustments to a visuomotor rotation. Neurobiol Learn\n[Mem 140:124\u2013133. CrossRef Medline](http://dx.doi.org/10.1016/j.nlm.2017.02.015)\nTrommersha\u00a8user J, Maloney LT, Landy MS (2008) Decision making, movement planning, and statistical decision theory. Trends Cogn Sci 12:291\u2013\n[297. CrossRef Medline](http://dx.doi.org/10.1016/j.tics.2008.04.010)\nTseng YW, Diedrichsen J, Krakauer JW, Shadmehr R, Bastian AJ (2007)\nSensory prediction errors drive cerebellum-dependent adaptation of\n[reaching. J Neurophysiol 98:54\u201362. CrossRef Medline](http://dx.doi.org/10.1152/jn.00266.2007)\nWalton ME, Kennerley SW, Bannerman DM, Phillips PE, Rushworth MF\n(2006) Weighing up the benefits of work: behavioral and neural analyses\n[of effort-related decision making. Neural Netw 19:1302\u20131314. CrossRef](http://dx.doi.org/10.1016/j.neunet.2006.03.005)\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/16949252)\nWolpert DM, Ghahramani Z, Jordan MI (1995) An internal model for sen[sorimotor integration. Science 269:1880\u20131882. CrossRef Medline](http://dx.doi.org/10.1126/science.7569931)\nWu SW, Delgado MR, Maloney LT (2009) Economic decision-making\ncompared with an equivalent motor task. Proc Natl Acad Sci U S A 106:\n[6088\u20136093. CrossRef Medline](http://dx.doi.org/10.1073/pnas.0900102106)\nWu SW, Delgado MR, Maloney LT (2011) The neural correlates of subjective utility of monetary outcome and probability weight in economic and\n[in motor decision under risk. J Neurosci 31:8822\u20138831. CrossRef](http://dx.doi.org/10.1523/JNEUROSCI.0540-11.2011)\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/21677166)\n\n\n",
  "markdown_text": "**Behavioral/Cognitive**\n\n## **Credit Assignment in a Motor Decision Making Task Is** **Influenced by Agency and Not Sensory Prediction Errors**\n\n\n**X** **Darius E. Parvin,** [1] **X** **Samuel D. McDougle,** [3,4] **X** **Jordan A. Taylor,** [3,4] **and X** **Richard B. Ivry** [1,2]\n\n1Department of Psychology, 2Helen Wills Neuroscience Institute, University of California, Berkeley, California 94720, 3Department of Psychology\nand [4] Princeton Neuroscience Institute, Princeton University, Princeton, New Jersey 08544\n\n\n**Failures to obtain reward can occur from errors in action selection or action execution. Recently, we observed marked differences in**\n**choice behavior when the failure to obtain a reward was attributed to errors in action execution compared with errors in action selection**\n**(McDougleetal.,2016). Specifically,participantsappearedtosolvethiscreditassignmentproblembydiscountingoutcomesinwhichthe**\n**absence of reward was attributed to errors in action execution. Building on recent evidence indicating relatively direct communication**\n**between the cerebellum and basal ganglia, we hypothesized that cerebellar-dependent sensory prediction errors (SPEs), a signal indicat-**\n**ing execution failure, could attenuate value updating within a basal ganglia-dependent reinforcement learning system. Here we com-**\n**pared the SPE hypothesis to an alternative, \u201ctop-down\u201d hypothesis in which changes in choice behavior reflect participants\u2019 sense of**\n**agency. In two experiments with male and female human participants, we manipulated the strength of SPEs, along with the participants\u2019**\n**sense of agency in the second experiment. The results showed that, whereas the strength of SPE had no effect on choice behavior,**\n**participants were much more likely to discount the absence of rewards under conditions in which they believed the reward outcome**\n**depended on their ability to produce accurate movements. These results provide strong evidence that SPEs do not directly influence**\n**reinforcement learning. Instead, a participant\u2019s sense of agency appears to play a significant role in modulating choice behavior when**\n**unexpected outcomes can arise from errors in action execution.**\n\n\n_**Key words:**_ **adaptation; agency; credit assignment; decision making; reinforcement; reward**\n\n\n**Significance Statement**\n\n\n**When learning from the outcome of actions, the brain faces a credit assignment problem: Failures of reward can be attributed to**\n**poor choice selection or poor action execution. Here, we test a specific hypothesis that execution errors are implicitly signaled by**\n**cerebellar-based sensory prediction errors. We evaluate this hypothesis and compare it with a more \u201ctop-down\u201d hypothesis in**\n**which the modulation of choice behavior from execution errors reflects participants\u2019 sense of agency. We find that sensory**\n**prediction errors have no significant effect on reinforcement learning. Instead, instructions influencing participants\u2019 belief of**\n**causal outcomes appear to be the main factor influencing their choice behavior.**\n\n\n**Introduction**\n\nConsider the situation in which a tennis player attempts a passing\nshot, only to have her opponent easily return it with a winning\nvolley. The player must decide whether the fault lies with her\n\n\nReceived Dec. 19, 2017; revised March 28, 2018; accepted April 7, 2018.\nAuthor contributions: D. E. P. wrote the first draft of the paper; D. E. P., S. D. M., J. A. T., and R. B. I. edited the paper;\nD. E. P., S. D. M., J. A. T., and R. B. I. designed research; D. E. P. performed research; D. E. P. and S. D. M. analyzed data;\nD. E. P., S. D. M., J. A. T., and R. B. I. wrote the paper.\nThis work was supported by the National Institute of Neurological Disorders and Stroke-National Institute of\nHealth, Grant NS092079 to R. B. I. and Grant NS084948 to J. A. T. We thank Matthew Boggess for help with data\ncollection; and Faisal Mushtaq for helpful discussions.\nThe authors declare no competing financial interests.\nCorrespondenceshouldbeaddressedtoDr. DariusE. Parvin, DepartmentofPsychology, UniversityofCalifornia,\nBerkeleyCA94720E-mail: darius@berkeleyedu\n\n\nchoice to hit a passing shot rather than a lob, or with her poor\nexecution of the passing shot. How the brain solves this credit\nassignment problem, whether to attribute successes or failures to\nthe selection or execution of actions, is poorly understood.\nReinforcement learning models that incorporate variables,\nsuch as reward magnitude and reward probability, have been\nquite successful in predicting choice behavior (Rescorla and\nWagner, 1972) and associated neuronal activity (Schultz et al.,\n1997). Missing from this equation, however, is the role of action\nexecution. These actions introduce a new set of variables to in\ncorporate into the decision-making process, such as the effort\nrequired to make a particular choice (Walton et al., 2006; Hartmann et al., 2013) or the probability of successfully executing the\n\n\ncally overlook the credit assignment problem, given the negligible\nrole of motor errors in standard reinforcement learning tasks.\nWe recently considered how processes specific to action execution could provide information required to solve this problem\n(McDougle et al., 2016). We compared a traditional, buttonpressing \u201cbandit task\u201d with a modified version in which participants indicated their choices by reaching to one of two targets. In\nthe former, the absence of reward provided information about\nthe outcome probabilities associated with each stimulus (e.g.,\naction selection error), whereas in the latter, the absence of reward provided information about reaching inaccuracy (e.g., action execution error), indicated by a visual cursor that landed\noutside the target. The results showed that participants\u2019 choice\nbehavior was less sensitive to action execution errors compared\nwith action selection errors. We proposed that this difference\nmay have been due to the presence of a motor execution error\nsignal in the reaching condition.\nIn the motor domain, sensory prediction errors (SPEs), the\ndiscrepancy between the predicted and actual sensory feedback,\nare used to correct the ongoing movements or to drive motor\nadaptation (Wolpert et al., 1995; Tseng et al., 2007). This signal\ncould be directly exploited by the reinforcement learning system\nto solve the credit assignment problem. That is, the presence of an\nSPE could signal that the absence of the expected outcome (negative reward prediction error [RPE]) should be attributed to an\nerror in movement execution rather than an erroneous choice.\nThis \u201cbottom-up\u201d SPE hypothesis could provide a functional\naccount of the relatively direct connections between the cerebellum, a critical component in the generation of SPEs, and the basal\nganglia, parietal lobe, and orbital prefrontal cortex, core structures in reinforcement learning.\nAlternatively, the credit assignment problem could be solved\nby a more \u201ctop-down\u201d process related to a sense of agency, operationalized here as the belief that success or failure in obtaining\na reward is determined by motor performance rather than the\nresult of a property of the choices themselves. Green et al. (2010)\nproposed a model in which agency influences the rate of change\nin the values associated with response choices. In our reaching\nversion of the bandit task, this would result in behavior consistent\nwith discounting RPEs on trials with negative outcomes.\nThe current study further explores how action execution errors modulate reinforcement learning. The SPE hypothesis predicts that choice behavior should be sensitive to manipulations of\nthe strength of the SPE, even if those manipulations are irrelevant\nto the reward outcomes. In contrast, the agency hypothesis predicts that manipulations of SPE strength should have a minimal\neffect on biases in choice behavior, and instead be influenced by\nthe belief that the outcomes are dependent on their motor accuracy. Using a reaching variant of the two-armed-bandit task, we\nmanipulated SPE by delaying reach feedback (Experiment 1), and\nby using \u201cclamped\u201d reaching feedback (Experiment 2). In Experiment 2, we also manipulated the task instructions to test whether\nbiases in choice behavior were modulated by the participants\u2019\nsense of agency.\n\n\n**Materials and Methods**\n\n_Participants._ All participants provided written consent, approved by the\ninstitutional review board at the University of California (Berkeley, CA).\nAll participants were right handed, based on self-report and an assessment with the Edinburgh Handedness Inventory (Oldfield, 1971). Participants received either class credit or monetary compensation.\n\n\nWacom, sampling rate \ufffd 200 Hz) while holding a digitizing pen, embedded in a custom handle. The stimuli were presented on a monitor that\nwas positioned above the tablet (53.2 cm \ufffd 30 cm, ASUS). The monitor\noccludedtheparticipant\u2019sviewoftheirhand. Theexperimentalsoftwarewas\n[custom written in MATLAB (The MathWorks) (RRID: SCR_001622) using](https://scicrunch.org/resolver/SCR_001622)\n[the Psychophysics toolbox extensions (Pelli, 1997) (RRID: SCR_002881).](https://scicrunch.org/resolver/SCR_002881)\n_Reaching task._ At the start of each trial, a white circle (diameter 1.2 cm)\nwas presented on the screen, indicating the start position (Fig. 1 _A_ ). The\nparticipant was instructed to move their hand to the start location. Feedback of hand position was indicated by a solid white circle (diameter 0.5\ncm). This feedback was only visible when the hand was within 2 cm of the\nstart position. After the cursor had been held in the start position for 1 s,\ntwo red circles (diameter 1 cm) were presented at a distance of 10 cm, at\n60\u00b0 and 120\u00b0 counter-clockwise relative to the right. The word \u201cGo\u201d\nappeared in the middle of the screen, instructing the participant to reach\nto one of the two circles. The participant was instructed to make a slicing\nmovement, attempting to pass through the selected target. Cursor feedback was removed once the movement was initiated. If the reach amplitude did not reach 10 cm within 1.5 s, the message \u201cPlease Reach Faster\u201d\nwas displayed and the trial was terminated. If the participant\u2019s reach\ndeviated too far from either target (angular error \ufffd20\u00b0), the message\n\u201cOut of Bounds\u201d was displayed. In both cases, the trial was immediately\nrepeated.\nIf the hand passed within 20\u00b0 of the target, one of two trial outcomes\noccurred. On rewarded trials, the target color changed to green, a pleasant \u201cding\u201d sound was played, and the number of points earned (1\u2013100)\nwas displayed above the chosen target. On unrewarded trials, the target\nremained red, an unpleasant \u201cbuzz\u201d sound was played, and the number\n\u201c0\u201d was displayed above the chosen target. A box on the top of the screen\nshowed the cumulative total of points earned.\n_Reward schedule._ To assess target choice preference independent of\nreaching accuracy, the reward schedules were predetermined; as such,\nthe outcomes were not contingent on whether or not the reaching movement actually intersected the selected target (with the exception of\nreaches judged to be out of bounds). Hit probability and reward functions were created using a bounded pseudo-sinusoidal function (Fig.\n1 _B_ ). These functions were mirrored for each target, such that the expected value for each target on a given trial was matched. For example, a\n\u201csafe\u201d target with a 90% hit probability and reward value of 10 points\nwould be paired with a matching risky target that had a 10% hit probability and rewarded 90 points. We operationally define risk in terms of\nthe probability of hitting the target. On hit trials, the participant received\nthe associated reward value for that trial; on miss trials, no points were\nawarded. The probability and reward functions were designed so that at\nmultiple points during the experiment, payoffs between the left and right\ntargets gradually shifted, allowing us to track the participant\u2019s choice\npreferences. The same reward schedule was used for all participants, with\nthe position of the targets counterbalanced.\n_Experiment 1._ Experiment 1 was designed to compare conditions in\nwhich reach errors were signaled by a strong or weak SPE ( _n_ \ufffd 20 per\ngroup; total _n_ \ufffd 60, 33 female, age range 18\u201325 years). At the location\nwhere the movement amplitude reached 10 cm, the cursor reappeared,\nproviding the participant with a feedback signal that indicated the accuracy of the reach (Fig. 1 _C_ ). Presuming that the participant had intended\nto hit the target, the difference between the center of the target and the\ncursor position indicated the SPE for that trial.\nGiven that the hit/miss outcomes were predetermined, it was necessary to alter the feedback on some of the trials. On trials where the reach\noutcome matched the predetermined outcome, the reach feedback was\nveridical: The feedback cursor would fall on the target on hit trials (22.5%\nof all trials) and off the target on miss trials (27.5% of all trials). On trials\nwhere the reach outcome and predetermined outcome did not match,\nthe reach feedback was manipulated. For \u201chits\u201d that had to be converted\nto \u201cmisses\u201d (25.5% of all trials), the cursor was displayed at a new location away from the target (in the same direction as the side of the target that\nwas hit). To mask the fact that the feedback was sometimes altered, the\ndistribution of the altered feedback signals was designed to closely match\n\n\n**Figure 1.** Experimental design. _**A**_, Trials began with participants moving their hand to place the cursor at the start position. They indicated their choice preference by performing a shooting\nmovement through the selected target. Visual feedback of the hand position was extinguished once the hand left the start position. In Experiment 1, visual feedback of the reach was provided on\nanimaginarycirclewitharadiusequaltothetargetdistance. Onhittrials,thetargetwouldturngreenandapleasant\u201cding\u201dsoundwasgenerated. Onmisstrials,thetargetwouldremainredand\nanunpleasant\u201cbuzz\u201dsoundwasgenerated. Thenumberofpointsearnedwasdisplayedabovethechosentarget(\u201c0\u201dinthecaseofamiss),alongwithacumulativetotalofpointsearneddisplayed\ninabox. _**B**_, Top, Rewardfunctions(leftaxis)andhitprobabilities(rightaxis)foreachtarget. Overtrials,thetargetsvaryintermsoftheirrelative\u201crisk\u201d(e.g.,highpayoffbutlowhitprobability)but\narealwaysmatchedintermsoftheexpectedpayoff. Bottom, Threegroupsweretestedwithdifferentfeedbackdelaysandintertrialintervals. ImmediateFeedbackandDelayedTrialsbothreceived\nimmediate reach feedback. Delayed Feedback received the same reach feedback but after a 2 s delay. _**C**_, Example feedback for hit and miss trials in Experiment 1. Veridical feedback was provided\nwhenparticipants\u2019actualaccuracy(hitormiss)matchedthepredeterminedoutcome. Fortrialswheretheydidnotmatch,thecursorwouldbebumpedinoroutofthetargetonthesameside,such\nthatparticipantswerenotawareoftheperturbation. _**D**_, InExperiment2,feedbackofreachingaccuracywasnotprovided. ForSPE\ufffd groups,onmisstrials,thefeedbackcursorwas\u201cclamped\u201dand\nalways presented at the same location between the two targets (regardless of which was chosen). On hit trials, no feedback cursor was presented. For SPE- groups, on all trials, no feedback cursor\nwas presented.\n\n\n**Figure 2.** Distribution of reach endpoints and feedback location. _**A**_, In Experiment 1, reach feedback was minimally altered to match the predetermined reward schedule. _**B**_, In Experiment 2,\nclampedfeedbackwasprovidedataninvariantlocation(90\u00b0)onmisstrialsfortheSPE [\ufffd] condition. Asaresult,theSPE [\ufffd] groupheadinganglesareshiftedawayfromthecenterrelativetotheSPE [\ufffd]\n\ngroup, due to implicit adaptation.\n\n\nfrom one side of a normal distribution with a SD of 4.65\u00b0, with the peak\ncentered on the edge of the target. Locations deviating further than 2\ntimesthedistribution\u2019sSD(9.3\u00b0)wereresampled. For\u201cmisses\u201dconvertedto\n\n\noriginal miss. We included the \u201cOut of Bounds\u201d criteria to ensure that the\nfeedback perturbations were relatively small, and thus prevent the participants from becoming aware of the feedback manipulation.\n\n\nprovided. Previous studies have demonstrated that delaying sensory\nfeedback by over 1 s can strongly attenuate the strength of an SPE (Held\net al., 1966; Kitazawa et al., 1995; Honda et al., 2012; Brudner et al., 2016;\nSchween and Hegele, 2017). In the Immediate Feedback group, the cursor reappeared as soon as the reach amplitude exceeded 10 cm (Fig. 1 _B_ ).\nIn the Delayed Feedback group, the cursor feedback was presented after\na 2 s delay. This manipulation confounds feedback delays and the time\nbetween successive trials. To unconfound these factors, we also tested a\nthird group who received immediate cursor feedback but then had to\nwait an additional 2 s before the start of the next trial (Delayed Trials).\n_Experiment 2._ In Experiment 2, we used a 2 \ufffd 2 factorial design ( _n_ \ufffd 20\nper group; total _n_ \ufffd 80, 51 female, age range 18\u201325 years). The first factor\nwas to test whether an explicit sense of agency would alter participants\u2019\nchoice behavior. The second was to provide a second test of the SPE\nhypothesis.\nIn our previous study, we found no effect of agency (McDougle et al.,\n2016); however, our manipulation, which involved instructing participants that they were either in control or not in control of the hit/miss\noutcomes, may have been complicated by the inclusion of reach feedback\nin the vicinity of the target. The reach feedback may have unintentionally\nswayed participants to believe that they were still in control, regardless of\nthe instructions. Here, we avoided this conflict by removing reach feedback completely. To manipulate a sense of agency, the participants were\ntold that miss trials were either related or not related to their reaching\naccuracy. In the former case, the participants were told that the trial\noutcome reflected whether their reach accurately intersected the chosen\ntarget (Agency [\ufffd] ). In the latter case, the participants were told that the\noutcome reflected a probability that a target choice would result in a\npayoff, independent of their reaching accuracy (Agency [\ufffd] ). Beyond this\ninstruction, the participants were not informed about the nature of the\nhit probabilities or reward schedule.\nWe also sought a second test of the SPE hypothesis, comparing conditions that did or did not include SPEs on miss trials. For participants in\nthe SPE [\ufffd] conditions, we used a variant of task irrelevant clamped feedback (Morehead et al., 2017; Kim et al., 2018) to elicit SPEs without\nconveying reaching performance: On miss trials, the cursor feedback was\nalways presented at a common location positioned between the two targets (90\u00b0) (Fig. 1 _D_ ), appearing as soon as the reach amplitude exceeded\n10 cm. The participants were fully informed that, regardless of which\ntarget was selected, the feedback would always appear straight ahead on\nunrewarded trials. Given the instructions and lack of spatial correlation\nbetween the feedback and reaching movement (Fig. 2 _B_ ), we assumed that\nthese participants would not confuse the clamped feedback as indicative\nof their reach angle. Nonetheless, based on our previous work with\nclamped feedback of this sort, we assumed that these conditions would be\nsufficient to elicit SPE-dependent adaptation and, indeed, confirmed this\nin a separate \u201cClamp-only\u201d control experiment (see \u201cClamp-only\u201d experiment below).\nParticipants in the SPE [\ufffd] conditions received clamped feedback on all\nmiss trials. This feedback signal was not presented to participants in the\nSPE [\ufffd] conditions. Neither group received cursor feedback on hit trials.\n_Experiment 2 block structure._ The experiment consisted of 30 baseline\ntrials, 400 decision making trials, and 30 aftereffect trials. The 400 decision making trials had the same reward schedule as Experiment 1. For the\nbaseline and aftereffect trials, only one of the two targets were presented\non each trial (location randomized), and the participant was instructed\nto reach to the target. A \u201cding\u201d indicated that the movement amplitude\nhad exceeded 10 cm. No information was provided concerning reaching\n\naccuracy.\nThe baseline and aftereffect trials were included to assess whether the\nclamped feedback was treated by the motor system as an SPE. If so, the\nheading direction in the aftereffect block should be shifted in the lateral\ndirection compared with the baseline block. Visuomotor adaptation was\noperationalized as a shift in heading angle in the aftereffect trials relative\nto baseline. The heading angle was defined as the angle between the hand\nposition when it crossed the target radius, the start position, and the\ntarget. The heading angle values for the 60\u00b0 target (to the right) were\n\n\ntion to the clamped feedback). All reported aftereffects were baseline\nsubtracted, where the baseline was defined as the mean of all baseline\ntrials.\n_Clamp-only experiment._ The design and logic of Experiment 2 rests on\nthe assumption that the clamped visual feedback is treated as an SPE\n(Morehead et al., 2017; Kim et al., 2018). Although the comparison of the\nbaseline and aftereffect blocks in Experiment 2 provides a test of this\nassumption, we thought it prudent to conduct a clamp-only experiment\nthat used a more traditional sensorimotor adaptation design, one in\nwhich the participants did not have to choose the reach target.\nReaches were made to a single target, displayed at either 60\u00b0 or 120\u00b0,\nthe locations used in Experiments 1 and 2 (see Fig. 4 _A_ ). The experiment\nconsisted of 30 baseline trials (15/target) in which no visual feedback was\nprovided, 120 \u201cclamp\u201d trials (60/target), and 10 aftereffect trials (5/target), again with no visual feedback. The trial structure was the same as in\nthe baseline and aftereffects blocks of Experiment 2.\nThe clamp-only experiment also provided an opportunity to test the\neffect of delayed visual feedback on sensorimotor adaptation, relevant to\nour manipulation in Experiment 1. Two groups were tested (14/group,\n14 female, age range 18\u201325 years), one in which the clamped feedback\nwas provided coincidentally with the reach endpoint (\u201cNo Delay\u201d), and a\nsecond in which the feedback was delayed by 2 s (\u201cDelay\u201d). If the clamp is\ntreated as an SPE, adaptation should be evident in the \u201cNo Delay\u201d group\nand abolished, or severely attenuated in the \u201cDelay\u201d group.\n_Statistical analysis._ The chosen sample sizes were based on our previous studies using the reaching variant of the two-armed bandit (McDougle et al., 2016) and the clamp method (Morehead et al., 2017; Kim et\nal., 2018). All _t_ tests were two-tailed and used a threshold for significance\n(\ufffd) of 0.05 unless stated otherwise. We computed the inverse Bayesfactor ( _BF_ 01) for our results from Experiment 1 to assess the likelihood of\nthe null hypothesis ( _H_ 0) relative to the SPE hypothesis ( _H_ 1). We used a\nmethod proposed by Rouder et al. (2009), using a prior for effect size\nfollowing a Cauchy distribution with a scale factor of 1. Here, _BF_ 01 \ufffd 1/3\ncan be considered as strong evidence in favor of the alternative hypothesis, _BF_ 01 \ufffd 3 as strong evidence in favor of the null hypothesis, and\nanything between is only considered weak or anecdotal (Dienes, 2014).\n\n\n**Results**\n\n**Experiment 1**\nIn Experiment 1, we set out to test the SPE hypothesis, the idea\nthat the operation of the reinforcement learning system is attenuated following trials in which the absence of a reward is attributed to an error in action execution rather than action selection.\nThe core prediction of this bottom-up hypothesis is that the\nstrength of the SPE signal should influence choice behavior. Participants were tested in a two-armed bandit task, indicating their\nchoices on each trial by reaching to one of two targets. In addition\nto receiving reward feedback, cursor feedback indicated the accuracy of the reach. We compared two groups, an Immediate\nFeedback group who saw the feedback cursor immediately at the\nend of the reach; and a Delayed Feedback group, for whom the\nappearance of the feedback cursor was delayed by 2 s. Based on\nprevious studies, the strength, or salience of SPE should be considerably attenuated in the Delayed Feedback group (Held et al.,\n1966; Kitazawa et al., 1995; Honda et al., 2012; Brudner et al.,\n2016; Schween and Hegele, 2017). Given that the 2 s feedback\ndelay also increases the time between successive trials, we also\ntested a Delayed Trials group in which the feedback cursor appeared immediately at the end of the reach, but with an extra 2 s\npause between trials. In this manner, we matched the trial-to-trial\ninterval of the Delayed Feedback and Delayed Trials groups.\nIn standard bandit tasks in which the outcome is not dependentonactionexecution,peopletypicallyshowapreferenceforthe\n\u201csafe\u201d target, consistent with a risk aversion bias (Kahneman and\n\n\n**Figure3.** Increasingthetrial-to-trialinterval,eitherbydelayingfeedbackorincreasingtheintertrialintervalresultedinaweakerpreferencefortheriskytarget. _**A**_, Meangroupchoicebehavior\nreveals overall preference for riskier target throughout the experiment. Colored lines indicate the proportion of choices made to the riskier target, averaged over participants in each condition\n(calculatedovera19-trialwindowmovingaverage). Therelative\u201criskiness\u201doftarget1andtarget2(determinedbythepredefinedrewardschedule)areshownforillustrativepurposes(blacksolid\nanddashedlines). _**B**_, Riskpreferencequantifiedastheratiooftrialswheretheriskiertargetwaschosenoverthetotalnumberoftrials. Allgroupsexhibitedapreferencefortheriskierchoice(\ufffd0.50),\nwiththiseffectsignificantlygreaterfortheIFgroupcomparedwiththeothertwo. IF, ImmediateFeedback; DF, DelayedFeedback; DT, DelayedTrials. Errorbarsindicate \ufffd1SEMoverparticipants.\n\n\na striking reversal of this preference when the choices were indicated\nby reaches, so that the failure to obtain a reward was attributed to a\nfailure of action execution. The SPE hypothesis predicts that this\nreversal is due to the presence of SPEs on miss trials. Consistent with\nthose results, the Immediate Feedback group and Delayed Trials\ngroup showed a consistent preference for the riskier target over the\ncourse of the experiment (Fig. 3 _A_ ). However, in contrast to the SPE\nhypothesis,theDelayedFeedbackgroupalsoshowedareversalofthe\nrisk aversion bias, even though we assume the strength of the SPE is\ngreatly attenuated by the delay (an assumption we confirm in\nClamp-only Experiment).\nFor each trial, we defined the risky target as the one with the\nlower hit probability, but higher payoff and, as such, the option\nwith a larger variance of potential outcomes (Kahneman and\nTversky, 1979; Caraco et al., 1980; Dayan and Niv, 2008; Schultz,\n2016). Using this definition, we quantified participants\u2019 choice\nbiases by calculating the ratio of trials in which they picked the\nriskier target over the total number of trials (excluding the few\nout of bounds trials). A one-way ANOVA revealed a significant\neffect of group on risk bias ( _F_ (2,57) \ufffd 4.65, _p_ \ufffd 0.01; Fig. 3 _B_ ).\n_Post hoc t_ tests using Bonferroni-adjusted \ufffd levels of 0.017\n(.05/3) were conducted. A numerical but nonsignificant difference (after correcting for multiple comparisons) existed between\nthe Immediate Feedback and Delayed Feedback groups ( _t_ (38) \ufffd\n2.13, _p_ \ufffd 0.04). This difference is in a direction consistent with\nthe hypothesis that SPE influences choice behavior. However, we\nobserved a significant difference between the Immediate Feedback and Delayed Trials groups ( _t_ (38) \ufffd 2.95, _p_ \ufffd 0.005), indicating that an increase in intertrial interval alone (i.e., without\nmanipulating the SPE) affected choice preference. The Delayed\nFeedback group had a numerically lower risk bias compared with\nthe Delayed Trials group, opposite to what the SPE hypothesis predicts, although this difference was nonsignificant ( _t_ (38) \ufffd 0.93, _p_ \ufffd\n0.36). An inverse Bayes factor comparing the odds of the hypothesis\nthat the Delayed Feedback and Delayed Trials risk biases were equal\n(null) versus the hypothesis that they were unequal provided only\nweak support in favor of the null ( _BF_ 01 \ufffd 2.95).\nTogether, these results fail to support the hypothesis that\nchoice biases are modulated by the strength of the SPE. The most\nparsimonious interpretation of the current results is that choice\nbiases in the current task decay as a function of the time between\nsuccessive trials, independent of the strength of the SPE. This\n\n\nmemory that could be used to adjust the next movement (see\nDiscussion).\n\n\n**Experiment 2**\nThe results of the first experiment indicate that SPE is not a\ncritical signal that directly modulates choice biases. An alternative hypothesis is that, due to the sense of agency associated with\nreaching (Green et al., 2010), people may be slow to update their\nestimates of action execution errors based on recent outcomes.\nFor example, the participants have a strong prior for their reaching competency and believe that their execution errors simply\nreflect motor noise, a variable that should operate randomly\nacross trials. We set out to test this hypothesis in Experiment 2,\ncomparing conditions in which participants were told that the\nabsence of reward was attributed to a failure in motor execution\n(Agency [\ufffd] ) to conditions in which the absence of reward was\nattributed to a property of the object (Agency [\ufffd] ). If the sense of\nagency is critical, we would expect participants to prefer the\n\u201csafe\u201d target in the latter conditions.\nWe also designed Experiment 2 to provide a second test of the\nSPE hypothesis. To that end, we compared conditions in which\nthe trial outcome included clamped cursor feedback (SPE [\ufffd] ) or\ndid not include this feedback (SPE [\ufffd] ). This feedback, when provided, was always presented at the same location midway between\nthe two targets, independent of their target choice. Based on previous work with clamped feedback (Morehead et al., 2017; Kim et\nal., 2018), we assumed that this signal would automatically be\ntreated by the motor system as an SPE, driving sensorimotor\nadaptation. However, given the results of Experiment 1, we expected that the presence or absence of SPE would not influence\nchoice behavior.\nWe first verified that clamped feedback, even if only presented\nat the end of the movement, was sufficient to produce adaptation\n(see Materials and Methods, Clamp-Only Experiment). Despite\nbeing informed about the nature of the clamped feedback and\ninstructed to ignore it, robust adaptation was observed when the\nclamped feedback was presented: During the clamp block, the\nheading angle for each target shifted in the opposite direction of\nthe cursor and an aftereffect was observed (Fig. 4 _B_ ). A _t_ test of the\nbaseline-subtracted final heading angle revealed the aftereffect\nbeing significantly \ufffd0 ( _t_ (13) \ufffd 4.65, _p_ \ufffd 0.001). Moreover, these\neffects were absent if the feedback was delayed by 2 s ( _t_ (13) \ufffd\n\n\n**Figure 4.** Clamp-only experiment showing sensorimotor adaptation from clamped feedback, but only if the feedback is immediate. _**A**_, Participants were instructed to reach toward the single\ntarget. Clampedfeedbackwouldalwaysappearstraightaheadattheendofthereach,regardlessoftheparticipant\u2019sheadingangle. _**B**_, Immediateclampedfeedback(\u201cNoDelay\u201d)elicitsasignificant\naftereffectintheexpecteddirectionforbothtargets. Noaftereffectisobservedwhentheclampedfeedbackisdelayedby2s(\u201c2sDelay\u201d). Linesrepresentmeanheadingangleoverparticipantsand\nshaded regions around the lines represent \ufffd1 SEM over participants. Gray regions represent baseline and aftereffect trials with no feedback.\n\n\n**Figure5.** Senseofagency,butnotpresenceofSPE,influenceschoicepreference. _**A**_, Headingangleofreachesrevealsthetimecourseofadaptation. Headingangleforthe60\u00b0targetareflipped\nsuchthatpositiveisinthedirectionofadaptation. Linesindicatemeanheadingangleoverparticipants. Shadedregionsaroundthelinesrepresent \ufffd1SEMoverparticipants. Grayregionsrepresent\nbaselineandaftereffecttrialswhereonlyonetargetwaspresentedandnoreachfeedbackwasprovided. _**B**_, Baseline-subtractedaftereffectsshowsignificantadaptationforbothSPE [\ufffd] conditions,\nandnonefortheSPE [\ufffd] conditions. _**C**_, GroupaveragedchoicebehaviorshowsabiastowardthesafetargetfortheAgency [\ufffd] conditions,andnobiasforAgency [\ufffd] conditions. Coloredlinesindicate\ntheproportionofchoicesmadetotheriskiertarget,averagedoverparticipantsineachcondition(calculatedovera19-trialwindowmovingaverage). Therelative\u201criskiness\u201doftarget1andtarget\n2 (determined by the predefined reward schedule) are shown for illustrative purposes (black solid and dashed lines). _**D**_, Risk preference quantified as the ratio of trials where the riskier target was\nchosen over the total number of trials. Choice bias is influenced by a sense of agency, rather than SPE.\n\n\nrobust implicit learning (Held et al., 1966; Kitazawa et al., 1995;\nHonda et al., 2012; Brudner et al., 2016; Schween and Hegele,\n2017).\nAdaptation also occurred in response to the clamped feedback\nin the main experiment. During the choice trials, heading angle\nagain shifted in the opposite direction of the cursor (Fig. 5 _A_ ), and\nthere was a pronounced aftereffect (Fig. 5 _B_ ). (Such an accumulation of adaptation leading to an aftereffect would not occur\nin Experiment 1, as errors were presented on both sides for\neach target). These effects were not observed for the groups in\nwhich the cursor was never presented (SPE-groups). A two-way\nANOVA comparing the heading angle in the aftereffect block to\nthe baseline block revealed a main effect of SPE ( _F_ (1,76) \ufffd 40.7, _p_ \ufffd\n0.001), but no effect of agency ( _F_ (1,76) \ufffd 1.05, _p_ \ufffd 0.31) or an interaction ( _F_ (1,76) \ufffd 0.38, _p_ \ufffd 0.54). We note that the magnitude of\n\n\nindicate that adaptation is influenced by a sense of agency, the\nparticipants in the Agency [\ufffd] group chose the risky target more\noften (see below), experienced more \u201cmiss trials,\u201d and thus received more SPEs.\nHaving established that the clamped feedback was an effective\nSPE, we next asked whether choice behavior was influenced by\nthe presence of an SPE, a sense of agency, or an interaction of\nthese variables. When participants were led to believe that the\nabsence of reward was due to an action execution error, they did\nnot show the same risk averse (\u201csafe\u201d) bias compared with when\nthey were told that the absence of reward reflected a probabilistic\nproperty of the target. As can be seen in Figure 5 _C_, _D_, the\nAgency [\ufffd] groups tracked the \u201csafe\u201d target, whereas the Agency [\ufffd]\n\ngroups showed no consistent bias in their choice behavior. In\ncontrast, the presence of an SPE had no influence on choice be\n\n**Figure6.** AgencymodelfitsforExperiment2. _**A**_, Simulationsbasedonfittedparametersproducepatternofriskbiasesthataresimilar\ntothoseobservedinthefourconditionsofExperiment2. _**B**_, Fittedlearningparameters(\ufffdpayoff and \ufffdprob)foreachcondition. Agency [\ufffd]\n\nconditions have a lower \ufffdprob than Agency [\ufffd] conditions, consistent with the hypothesis that participants treat hit probabilities as less\ntemporallydependentwhentheyhaveasenseofagency. Errorbarsindicate \ufffd1SEMoverparticipants.\n\n\n_p_ \ufffd 0.78), and there was no interaction between these variables\n( _F_ (1,76) \ufffd 0.03, _p_ \ufffd 0.87).\nIn summary, the results of Experiment 2 indicate that the\npresence of SPE, although leading to adaptation, was not sufficient to influence decision making. In contrast, variation in the\nsense of agency did influence choice behavior, with participants\nmore likely to choose the risky target when they believed they\nwere in control, at least to some degree, of the trial outcome.\n\n\n**Model-based analysis of the agency hypothesis**\nExperiment 2 was designed to examine whether choice behavior\nis affected when a sense of agency is explicitly manipulated, operationalized as the belief that outcomes are the result of motor\nperformance. We hypothesized that a sense of agency would influence behavior by reducing the influence of temporal dependency of trial outcomes (Green et al., 2010). Specifically, if motor\nerrors are assumed to reflect random noise in the Agency [\ufffd] conditions, recent hits and misses would not be informative about\nfuture hits and misses. In contrast, hit and miss outcomes are\nindependent of the agent\u2019s motor accuracy in the Agency [\ufffd] conditions; thus, recent outcomes should provide useful information\nabout future outcomes.\nToevaluatewhetherthisagencyhypothesiscouldaccountforour\nobserved behavior in Experiment 2, we developed a reinforcement\nlearning model to capture how temporal dependency could influence choice behavior. In this model, the estimated hit probabilities\n_p\u02c6_ t( _x_ ) and payoffs _E_ t( _x_ ) for each target _x_ on trial _t_ are updated on a\ntrial-by-trial basis, based on the differences between the actual and\npredictedoutcomes(McDougleetal.,2016). Thedegreeoftemporal\ndependence is captured by two learning rate parameters, \ufffdprob and\n\ufffdpayoff, that correspond to the proportion that these estimates are\nupdated based on the previous trial outcome as follows:\n\n\n\ufffd _prob_, _t_ \ufffd _rt_ \ufffd _p\u02c6t_ \ufffd _x_ \ufffd\n\n\n\ufffd _payoff_, _t_ \ufffd _rt_ \ufffd _Et_ \ufffd _x_ \ufffd\n\n\n_p\u02c6t_ \ufffd1\ufffd _x_ \ufffd \ufffd _p\u02c6t_ \ufffd _x_ \ufffd \ufffd\ufffd _prob_ \ufffd _prob_, _t_\n# Et \ufffd1\ufffd x \ufffd \ufffd \ufffd EEt \ufffd t \ufffd xx \ufffd\ufffd, \ufffd\ufffd payoff \ufffd payoff, t, if missif hitt t\n\n\nwhere _p\u02c6_ t( _x_ ) takes on a value between 0 and\n1 for each target, representing the probability that a reach to that target will result\nin a hit. The hit or miss outcome (independent of reward), _r_ *, is coded as a 1 or 0\nfor a hit or a miss, respectively. Differences between the estimated hit probability and the actual outcome \ufffdprob,t, are\nmultiplied by \ufffdpayoff and added to the estimated hit probability for the next trial.\nAs a result, \ufffdprob captures the degree to\nwhich a participant updates the estimates\nof hit probability as a result of previous\ntrials. By fitting \ufffdprob as a free parameter\nfor each participant, we can estimate the\ndegree to which they behaved as though\nthey believed the hit outcomes were tem\n)foreachcondition. Agency [\ufffd]\n\nporally dependent, with higher values\nrepresenting stronger temporal dependence. If participants treat motor execution errors as temporally independent\nwhen they believe the outcomes are dependent on their reaching accuracy (Agency [\ufffd] groups), we\nshould observe lower \ufffdprob compared with when they believe the\noutcomes are not dependent on reaching accuracy (Agency [\ufffd]\n\ngroups).\nEstimated payoffs were updated in a similar manner to estimated probabilities. However, for payoffs, _r_ takes on values from\n1 to 100 according to the observed payoff, and the update only\noccurs following hit trials. This conditional is a central component of the model, as it effectively separates trials in which outcomes are due to motor errors from trials that result in standard\nRPEs. \ufffdpayoff is fit as a free parameter for each participant and also\nreflects the degree of temporal dependence in payoffs. Because\nthe payoff amounts were not dependent on hit accuracy, but\nrather a property of the target, we expected \ufffdpayoff to be approximately constant across all the experimental conditions.\nEstimated target values _V_ ( _x_ ) were transformed into probabilities using a standard softmax function. The inverse temperature\nparameter (\ufffd) for the softmax was fit with one common value\nfor all 80 participants in Experiment 2, resulting in 161 free\nparameters in total (one \ufffdprob and \ufffdpayoff per participant, and\none common \ufffd). Free parameter estimates were made using\nthe fmincon function in MATLAB, which minimized the negative log likelihood of the choices for the parameters. The\nlearning rates (\ufffdprob and \ufffdpayoff) were bounded between 0 and\n1, and the inverse temperature parameter (\ufffd) was bounded\nbetween 0.05 and 10.\nWe fit the learning parameters, then generated choice data to\nsimulate risk preferences. The agency model was capable of simulating the pattern of behavioral risk biases observed in Experiment 2 (Fig. 6 _A_ ). Consistent with the predictions of the agency\nhypothesis, the groups that were told their reaching accuracy did\nnot influence hit probability (Agency [\ufffd] groups) had a higher\n\ufffdprobability value than the groups that were told their reaching\naccuracy determined the hit outcomes (Agency [\ufffd] groups) (Fig.\n6 _B_ ). A two-way ANOVA revealed a significant effect of agency on\n\ufffdprob ( _F_ (1,76) \ufffd 7.85, _p_ \ufffd 0.01), no effect of SPE ( _F_ (1,76) \ufffd 1.82,\n_p_ \ufffd 0.18), and no interaction between the two ( _F_ (1,76) \ufffd 0.08, _p_ \ufffd\n0.78). Also consistent with the agency hypothesis, a two-way\nANOVArevealednosignificanteffectsofagencyon \ufffdpayoff ( _F_ (1,76) \ufffd\n\n\nThese results support the hypothesis that differences in\nchoice behavior across groups were mainly influenced by the\ndegree to which they treated hit probabilities as being temporally dependent, with a belief of agency leading to more temporal independence.\n\n\n**Discussion**\n\nPeople are less sensitive to unrewarded outcomes when they are\nattributed to errors in action execution rather than action selection (McDougle et al., 2016). The main objective of this study was\nto evaluate different cues that could be used to solve this credit\nassignment problem. In earlier work, we had proposed a bottom-up\nhypothesis by which cerebellar-dependent SPEs were exploited\nby the reinforcement learning system, signaling the presence of\nan execution error (McDougle et al., 2016). By this model, SPEs\nprovide a salient signal that the trial outcome should be attributed to the agent (i.e., execution error), rather than the chosen\nobject (i.e., selection error). We tested this hypothesis in Experiment 1 by manipulating the strength of SPE and in Experiment 2\nby presenting movement-irrelevant SPEs. In both cases, the results failed to support the hypothesis that SPE played a critical\nrole in producing the observed bias in choice behavior. Instead,\nwe found that the sense of agency had a significant effect on\nchoice behavior, suggesting that the credit assignment problem\nmay be solved in a more indirect, top-down manner.\n\n\n**Salience of SPEs does not influence biases in choice behavior**\nThe strongest argument against the SPE hypothesis comes from\nExperiment 1. Here we compared conditions in which the feedback cursor was presented immediately at the end of the movement or after a 2 s delay. Previous work, as well as our clamp-only\ncontrol experiment, has shown that a 2 s feedback delay strongly\nattenuates sensorimotor adaptation (Held et al., 1966; Kitazawa\net al., 1995; Honda et al., 2012; Brudner et al., 2016; Schween and\nHegele, 2017), presumably because the delay weakens the SPE. If\nSPE directly modulates choice preferences, then we expect participants to become more sensitive to unrewarded outcomes\nwhen the feedback was delayed. Although this effect was observed, a similar pattern was elicited when the intertrial interval\nwas extended by 2 s, even if the cursor feedback was immediate.\nThus, the most parsimonious account of these results is that the\ntime between successive choices, rather than SPE, decreased sensitivity to unrewarded outcomes.\nWhy might an increase in the intertrial interval change choice\npreferences? One hypothesis is that some form of iconic motor\nmemory is strong when the interval is short (Adams and Dijkstra,\n1966; Posner and Konick, 1966; Laabs, 1973; Annett, 1995; Miyamoto et al., 2014), leading the participants to believe they can\ncorrect the execution error. However, we found no evidence that\nparticipants showed a stronger adjustment in reach trajectories in\nthe Immediate Feedback condition compared with when the\nfeedback or intertrial interval was extended: The mean proportion of the error corrected on trials where feedback was artificially\nperturbed was 0.57 (SE \ufffd 0.04) for the Immediate Feedback\ncondition, 0.57 (0.08) for the Delayed Feedback condition, and\n0.53 (0.04) for the Delayed Trials conditions. A one-way ANOVA\non the regression between error and change in heading angle\nrevealed no effect of group ( _F_ (2,57) \ufffd 0.12, _p_ \ufffd 0.89). An alternative hypothesis is that the longer intertrial interval resulted in\nmore time discounting of the potential rewards for each target\n\n\nThe results of Experiment 2 provide further evidence against\nthe SPE hypothesis. Here we used a method in which the SPE\nsignal is not contingent on movement accuracy. Consistent with\nour previous work, this method was sufficient to produce adaptation in the reaching behavior of the participants. Nonetheless,\nchoice biases were similar, regardless of whether this signal was\npresent. Together, the results argue against a simple, bottom-up\nmodel in which an SPE signal is sufficient to attenuate value\nupdates when the outcome error is attributed to a failure in motor execution.\n\n\n**Choice biases are influenced by a sense of agency**\nThe results of the present study point toward a more top-down\nmechanism for solving the credit assignment required to differentiate execution and selection errors. This was most clearly\nobserved in the results of Experiment 2, where sensitivity to\nunrewarded outcomes was reduced when the instructions emphasized that the participants had some degree of agency in determining the outcome, with agency operationalized as the belief\nthat outcomes are dependent on one\u2019s motor performance. Similarly, Green et al. (2010) found that choice behavior could be\ndramatically altered by instructing participants that the trial outcome was either determined by the computer or contingent on\nmovement execution. Computationally, they suggested that people assume weaker temporal dependence between successive\nevents when the outcomes depend on motor output, given that\nerrors from motor noise are assumed to be random. Properties of\nthe object, however, may be more temporally dependent (e.g., the\ntarget with the high payoff on the previous trial is likely to yield a\nhigh payoff on the next trial).\nIn modeling the data from Experiment 2, we adopted an operational definition of agency introduced by Green et al. (2010),\nnamely, that a sense of agency will cause choices to be more\ntemporally independent. Consistent with the agency hypothesis,\nthe fits showed that participants in conditions of high agency\nwere less likely to behave as though hit outcomes were temporally\ndependent. In other words, by treating execution errors as\nthough they were random events and unlikely to occur again,\nthey were more likely to choose the target with the higher expected payoff. Participants in the low agency condition, however,\nwere more likely to behave as though misses were a property of\nthe target and, therefore, were biased to avoid the target which\nresulted in more misses.\nWe note that, in our earlier study (McDougle et al., 2016), we\nhad included a similar manipulation of a sense of control, informing participants that the position of the feedback cursor was\neither dependent or independent of their movement. Contrary to\nthe current results, we observed no effect of agency on choice\nbehavior when an SPE-like signal was present. However, the feedback cursor still appeared near the selected target, either as veridical feedback or in a slightly shifted position. It is possible that,\ndespite the instructions, the correlation between their movements and sensory feedback may have led the participants to\nbelieve, implicitly or explicitly, that they could control the reward\noutcomes. The clamped feedback used in Experiment 2 avoids\nthis problem because the feedback was spatially independent of\nthe movement.\nA similar explanation may also account for the betweenexperiment differences in choice behavior observed in conditions\nin which the participants were instructed to believe they were in\ncontrol of the trial outcomes. Although the reward schedules\n\n\nThis was verified in a _post hoc_ analysis, restricted to the Immediate\nFeedback condition in Experiment 1 and the two Agency [\ufffd]\n\ngroups in Experiment 2 ( _t_ (58) \ufffd 4.25, _p_ \ufffd 0.001). The main difference between these conditions was that endpoint reach feedback was provided in Experiment 1, but not Experiment 2. The\nendpoint feedback not only provided a salient cue for motor\nperformance, but also signaled a strong causal relationship association between trials in which the cursor hit the target and the\nparticipant being awarded points. These signals would likely increase the participants\u2019 confidence that the outcomes reflect their\nmotor performance, increasing their sense of agency and, thus,\nproduce a stronger risk bias.\nIn addition to an overall sense of agency, there is another way\nin which reach feedback might influence choice behavior. The\npresence of reach feedback results in salient, \u201cnear miss\u201d trials.\nThese have been shown, at least under some conditions, to produce similar hemodynamic responses as are observed with rewarded trials (Clark et al., 2009). Treating these near miss\noutcomes as rewarding, even if only slightly, would result in a\nstronger risk bias when reach feedback was present in Experiment\n1, but not in Experiment 2.\n\n\n**Mechanistic considerations for the modulation of**\n**reinforcement learning by execution errors**\nAs noted in the Introduction, distinguishing between action execution and action selection errors is important to optimize\nchoice behavior. Knocking over a cup of coffee should not make\nus dislike coffee, even though we failed to obtain an expected\nreward. Current models of decision making tend to be based on\ntasks in which execution errors are absent; yet these systems\nevolved in organisms in which outcomes almost always reflected\nthe interaction of processes involved in selection and execution.\nWe can envision two ways in which an execution error might gate\nvalue updating. The negative RPE signals associated with unsuccessful outcomes might be attenuated. Or the operation by which\nthese signals modify value representations might be disrupted.\nThe SPE hypothesis was motivated, in part, by consideration\nof recently described projections between the cerebellum and\nbasal ganglia (Hoshi et al., 2005; Bostan et al., 2010; Chen et al.,\n2014) and association areas of the cerebral cortex implicated in\nvalue representation (O\u2019Doherty, 2004; Choi et al., 2012). We\nhypothesized that execution error signals, which evolved to keep\nthe sensorimotor system calibrated, may have come to be exploited by the reinforcement learning system. However, the results from the current experiments provide strong evidence\nagainst this simple, bottom-up account of how a decision-making\nsystemmightdistinguishbetweenactionexecutionandactionselection errors.\nInstead, the current results suggest that this gating process is\ndriven by explicit knowledge about the source of errors, information that is dependent on a sense of agency. This contextual\nknowledge could have a direct influence on how RPEs are computed or used to update value representations. The recruitment\nof working memory (Collins et al., 2017) and explicit knowledge\nabout task contingencies (Li et al., 2011) have been shown to\naffect hemodynamic signatures of RPEs in ventral striatum and\nventromedial prefrontal cortex. In a similar fashion, top-down\nknowledge about the success or failure of action execution could\nprovide a similar modulatory signal, either to a system generating\nRPEs or using this information to update value representations.\n\n\nsensitive to the intersection of action execution and action\n\nselection.\n\n\n**References**\nAdams JA, Dijkstra S (1966) Short-term memory for motor responses. J Exp\n[Psychol 71:314\u2013318. CrossRef Medline](http://dx.doi.org/10.1037/h0022846)\nAnnett J (1995) Motor imagery: perception or action? Neuropsychologia\n[33:1395\u20131417. CrossRef Medline](http://dx.doi.org/10.1016/0028-3932(95)00072-B)\nBostan AC, Dum RP, Strick PL (2010) The basal ganglia communicate with\n[the cerebellum. Proc Natl Acad Sci U S A 107:8452\u20138456. CrossRef](http://dx.doi.org/10.1073/pnas.1000496107)\n\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/20404184)\nBrudner SN, Kethidi N, Graeupner D, Ivry RB, Taylor JA (2016) Delayed\nfeedback during sensorimotor learning selectively disrupts adaptation but\n[not strategy use. J Neurophysiol 115:1499\u20131511. CrossRef Medline](http://dx.doi.org/10.1152/jn.00066.2015)\nCaraco T, Martindale S, Whittam TS (1980) An empirical demonstration of\n[risk-sensitive foraging preferences. Anim Behav 28:820\u2013830. CrossRef](http://dx.doi.org/10.1016/S0003-3472(80)80142-4)\nChen CH, Fremont R, Arteaga-Bracho EE, Khodakhah K (2014) Short latency cerebellar modulation of the basal ganglia. Nat Neurosci 17:1767\u2013\n[1775. CrossRef Medline](http://dx.doi.org/10.1038/nn.3868)\nChoi EY, Yeo BT, Buckner RL (2012) The organization of the human striatum estimated by intrinsic functional connectivity. J Neurophysiol 108:\n[2242\u20132263. CrossRef Medline](http://dx.doi.org/10.1152/jn.00270.2012)\nClark L, Lawrence AJ, Astley-Jones F, Gray N (2009) Gambling near-misses\nenhance motivation to gamble and recruit win-related brain circuitry.\n[Neuron 61:481\u2013490. CrossRef Medline](http://dx.doi.org/10.1016/j.neuron.2008.12.031)\nCollins AG, Ciullo B, Frank MJ, Badre D (2017) Working memory load\n[strengthens reward prediction errors. J Neurosci 37:4332\u20134342. CrossRef](http://dx.doi.org/10.1523/JNEUROSCI.2700-16.2017)\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/28320846)\nDayan P, Niv Y (2008) Reinforcement learning: the good, the bad and the\n[ugly. Curr Opin Neurobiol 18:185\u2013196. CrossRef Medline](http://dx.doi.org/10.1016/j.conb.2008.08.003)\nDienes Z (2014) Using Bayes to get the most out of non-significant results.\n[Front Psychol 5:781. CrossRef Medline](http://dx.doi.org/10.3389/fpsyg.2014.00781)\nFrederick S, Loewenstein G, O\u2019Donoghue T (2002) Time discounting and\n[time preference: a critical review. J Econ Lit 40:351\u2013401. CrossRef](http://dx.doi.org/10.1257/jel.40.2.351)\nGreen CS, Benson C, Kersten D, Schrater P (2010) Alterations in choice\nbehavior by manipulations of world model. Proc Natl Acad Sci U S A\n[107:16401\u201316406. CrossRef Medline](http://dx.doi.org/10.1073/pnas.1001709107)\nHartmann MN, Hager OM, Tobler PN, Kaiser S (2013) Parabolic discounting of monetary rewards by physical effort. Behav Processes 100:192\u2013196.\n[CrossRef Medline](http://dx.doi.org/10.1016/j.beproc.2013.09.014)\nHeld R, Efstathiou A, Greene M (1966) Adaptation to displaced and delayed\nvisual feedback from the hand. J Exp Psychol 72:887\u2013891.\nHonda T, Hirashima M, Nozaki D (2012) Habituation to feedback delay\nrestores degraded visuomotor adaptation by altering both sensory prediction error and the sensitivity of adaptation to the error. Front Psychol\n[3:540. CrossRef Medline](http://dx.doi.org/10.3389/fpsyg.2012.00540)\nHoshi E, Tremblay L, Fe\u00b4ger J, Carras PL, Strick PL (2005) The cerebellum\n[communicates with the basal ganglia. Nat Neurosci 8:1491\u20131493. CrossRef](http://dx.doi.org/10.1038/nn1544)\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/16205719)\nKahneman D, Tversky A (1979) Prospect theory: an analysis of decision\n[under risk. Econometrica 47:263\u2013291. CrossRef](http://dx.doi.org/10.2307/1914185)\nKim HE, Morehead JR, Parvin DE, Moazzezi R, Ivry RB (2018) Invariant\nerrors reveal limitations in motor correction rather than constraints on\n[error sensitivity. Commun Biol 1:19. CrossRef](http://dx.doi.org/10.1038/s42003-018-0021-y)\nKitazawa S, Kohno T, Uka T (1995) Effects of delayed visual information on\nthe rate and amount of prism adaptation in the human. J Neurosci 15:\n[7644\u20137652. CrossRef Medline](http://dx.doi.org/10.1523/JNEUROSCI.15-11-07644.1995)\nLaabs GJ (1973) Retention characteristics of different reproduction cues in\n[motor short-term memory. J Exp Psychol 100:168\u2013177. CrossRef](http://dx.doi.org/10.1037/h0035502)\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/4744492)\nLandy MS, Trommersha\u00a8user J, Daw ND (2012) Dynamic estimation of\ntask-relevant variance in movement under risk. J Neurosci 32:12702\u2013\n[12711. CrossRef Medline](http://dx.doi.org/10.1523/JNEUROSCI.6160-11.2012)\nLi J, Delgado MR, Phelps EA (2011) How instructed knowledge modulates\nthe neural systems of reward learning. Proc Natl Acad Sci U S A 108:55\u2013\n[60. CrossRef Medline](http://dx.doi.org/10.1073/pnas.1014938108)\nMcDougle SD, Boggess MJ, Crossley MJ, Parvin D, Ivry RB, Taylor JA (2016)\nCredit assignment in movement-dependent reinforcement learning. Proc\n[Natl Acad Sci U S A 113:6797\u20136802. CrossRef Medline](http://dx.doi.org/10.1073/pnas.1523669113)\nMiyamoto YR, Wang SX, Brennan AE, Smith MA (2014) Distinct forms of\n\n\ntional and Computational Motor Control, Washington DC, District of\nColumbia.\n\nMorehead JR, Taylor JA, Parvin DE, Ivry RB (2017) Characteristics of implicit sensorimotor adaptation revealed by task-irrelevant clamped feed[back. J Cogn Neurosci 29:1061\u20131074. CrossRef Medline](http://dx.doi.org/10.1162/jocn_a_01108)\nNiv Y, Edlund JA, Dayan P, O\u2019Doherty JP (2012) Neural prediction errors\nreveal a risk-sensitive reinforcement-learning process in the human\n[brain. J Neurosci 32:551\u2013562. CrossRef Medline](http://dx.doi.org/10.1523/JNEUROSCI.5498-10.2012)\nO\u2019Doherty JP (2004) Reward representations and reward-related learning\nin the human brain: insights from neuroimaging. Curr Opin Neurobiol\n[14:769\u2013776. CrossRef Medline](http://dx.doi.org/10.1016/j.conb.2004.10.016)\n\nOldfield RC (1971) The assessment and analysis of handedness: the Edin[burgh Inventory. Neuropsychologia 9:97\u2013113. CrossRef Medline](http://dx.doi.org/10.1016/0028-3932(71)90067-4)\nPelli DG (1997) The VideoToolbox software for visual psychophysics:\n[transforming numbers into movies. Spat Vis 10:437\u2013442. CrossRef](http://dx.doi.org/10.1163/156856897X00366)\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/9176953)\n\nPosner MI, Konick AF (1966) Short-term retention of visual and kinesthetic\n[information. Organ Behav Hum Perform 1:71\u201386. CrossRef](http://dx.doi.org/10.1016/0030-5073(66)90006-7)\nRescorla RA, Wagner AR (1972) A theory of Pavlovian conditioning: variations in the effectiveness of reinforcement and nonreinforcement. In:\n\nClassical conditioning, Vol II: Current research and theory (Black AH,\nProkasy WF, eds), pp 64\u201399. New York, NY: Appleton-Century-Crofts.\nRouder JN, Speckman PL, Sun D, Morey RD, Iverson G (2009) Bayesian _t_\ntests for accepting and rejecting the null hypothesis. Psychon Bull Rev\n[16:225\u2013237. CrossRef Medline](http://dx.doi.org/10.3758/PBR.16.2.225)\n\n\nSchultz W (2016) Dopamine reward prediction error coding. Dialogues\n[Clin Neurosci 18:23\u201332. Medline](http://www.ncbi.nlm.nih.gov/pubmed/27069377)\nSchultz W, Dayan P, Montague PR (1997) A neural substrate of prediction\n[and reward. Science 275:1593\u20131599. CrossRef Medline](http://dx.doi.org/10.1126/science.275.5306.1593)\nSchween R, Hegele M (2017) Feedback delay attenuates implicit but facilitates explicit adjustments to a visuomotor rotation. Neurobiol Learn\n[Mem 140:124\u2013133. CrossRef Medline](http://dx.doi.org/10.1016/j.nlm.2017.02.015)\nTrommersha\u00a8user J, Maloney LT, Landy MS (2008) Decision making, movement planning, and statistical decision theory. Trends Cogn Sci 12:291\u2013\n[297. CrossRef Medline](http://dx.doi.org/10.1016/j.tics.2008.04.010)\nTseng YW, Diedrichsen J, Krakauer JW, Shadmehr R, Bastian AJ (2007)\nSensory prediction errors drive cerebellum-dependent adaptation of\n[reaching. J Neurophysiol 98:54\u201362. CrossRef Medline](http://dx.doi.org/10.1152/jn.00266.2007)\nWalton ME, Kennerley SW, Bannerman DM, Phillips PE, Rushworth MF\n(2006) Weighing up the benefits of work: behavioral and neural analyses\n[of effort-related decision making. Neural Netw 19:1302\u20131314. CrossRef](http://dx.doi.org/10.1016/j.neunet.2006.03.005)\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/16949252)\nWolpert DM, Ghahramani Z, Jordan MI (1995) An internal model for sen[sorimotor integration. Science 269:1880\u20131882. CrossRef Medline](http://dx.doi.org/10.1126/science.7569931)\nWu SW, Delgado MR, Maloney LT (2009) Economic decision-making\ncompared with an equivalent motor task. Proc Natl Acad Sci U S A 106:\n[6088\u20136093. CrossRef Medline](http://dx.doi.org/10.1073/pnas.0900102106)\nWu SW, Delgado MR, Maloney LT (2011) The neural correlates of subjective utility of monetary outcome and probability weight in economic and\n[in motor decision under risk. J Neurosci 31:8822\u20138831. CrossRef](http://dx.doi.org/10.1523/JNEUROSCI.0540-11.2011)\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/21677166)\n\n\n",
  "sections": {
    "preamble": "**Behavioral/Cognitive**\n\n## **Credit Assignment in a Motor Decision Making Task Is** **Influenced by Agency and Not Sensory Prediction Errors**\n\n\n**X** **Darius E. Parvin,** [1] **X** **Samuel D. McDougle,** [3,4] **X** **Jordan A. Taylor,** [3,4] **and X** **Richard B. Ivry** [1,2]\n\n1Department of Psychology, 2Helen Wills Neuroscience Institute, University of California, Berkeley, California 94720, 3Department of Psychology\nand [4] Princeton Neuroscience Institute, Princeton University, Princeton, New Jersey 08544\n\n\n**Failures to obtain reward can occur from errors in action selection or action execution. Recently, we observed marked differences in**\n**choice behavior when the failure to obtain a reward was attributed to errors in action execution compared with errors in action selection**\n**(McDougleetal.,2016). Specifically,participantsappearedtosolvethiscreditassignmentproblembydiscountingoutcomesinwhichthe**\n**absence of reward was attributed to errors in action execution. Building on recent evidence indicating relatively direct communication**\n**between the cerebellum and basal ganglia, we hypothesized that cerebellar-dependent sensory prediction errors (SPEs), a signal indicat-**\n**ing execution failure, could attenuate value updating within a basal ganglia-dependent reinforcement learning system. Here we com-**\n**pared the SPE hypothesis to an alternative, \u201ctop-down\u201d hypothesis in which changes in choice behavior reflect participants\u2019 sense of**\n**agency. In two experiments with male and female human participants, we manipulated the strength of SPEs, along with the participants\u2019**\n**sense of agency in the second experiment. The results showed that, whereas the strength of SPE had no effect on choice behavior,**\n**participants were much more likely to discount the absence of rewards under conditions in which they believed the reward outcome**\n**depended on their ability to produce accurate movements. These results provide strong evidence that SPEs do not directly influence**\n**reinforcement learning. Instead, a participant\u2019s sense of agency appears to play a significant role in modulating choice behavior when**\n**unexpected outcomes can arise from errors in action execution.**\n\n\n_**Key words:**_ **adaptation; agency; credit assignment; decision making; reinforcement; reward**\n\n\n**Significance Statement**\n\n\n**When learning from the outcome of actions, the brain faces a credit assignment problem: Failures of reward can be attributed to**\n**poor choice selection or poor action execution. Here, we test a specific hypothesis that execution errors are implicitly signaled by**\n**cerebellar-based sensory prediction errors. We evaluate this hypothesis and compare it with a more \u201ctop-down\u201d hypothesis in**\n**which the modulation of choice behavior from execution errors reflects participants\u2019 sense of agency. We find that sensory**\n**prediction errors have no significant effect on reinforcement learning. Instead, instructions influencing participants\u2019 belief of**\n**causal outcomes appear to be the main factor influencing their choice behavior.**\n\n",
    "introduction": "\nConsider the situation in which a tennis player attempts a passing\nshot, only to have her opponent easily return it with a winning\nvolley. The player must decide whether the fault lies with her\n\n\nReceived Dec. 19, 2017; revised March 28, 2018; accepted April 7, 2018.\nAuthor contributions: D. E. P. wrote the first draft of the paper; D. E. P., S. D. M., J. A. T., and R. B. I. edited the paper;\nD. E. P., S. D. M., J. A. T., and R. B. I. designed research; D. E. P. performed research; D. E. P. and S. D. M. analyzed data;\nD. E. P., S. D. M., J. A. T., and R. B. I. wrote the paper.\nThis work was supported by the National Institute of Neurological Disorders and Stroke-National Institute of\nHealth, Grant NS092079 to R. B. I. and Grant NS084948 to J. A. T. We thank Matthew Boggess for help with data\ncollection; and Faisal Mushtaq for helpful discussions.\nThe authors declare no competing financial interests.\nCorrespondenceshouldbeaddressedtoDr. DariusE. Parvin, DepartmentofPsychology, UniversityofCalifornia,\nBerkeleyCA94720E-mail: darius@berkeleyedu\n\n\nchoice to hit a passing shot rather than a lob, or with her poor\nexecution of the passing shot. How the brain solves this credit\nassignment problem, whether to attribute successes or failures to\nthe selection or execution of actions, is poorly understood.\nReinforcement learning models that incorporate variables,\nsuch as reward magnitude and reward probability, have been\nquite successful in predicting choice behavior (Rescorla and\nWagner, 1972) and associated neuronal activity (Schultz et al.,\n1997). Missing from this equation, however, is the role of action\nexecution. These actions introduce a new set of variables to in\ncorporate into the decision-making process, such as the effort\nrequired to make a particular choice (Walton et al., 2006; Hartmann et al., 2013) or the probability of successfully executing the\n\n\ncally overlook the credit assignment problem, given the negligible\nrole of motor errors in standard reinforcement learning tasks.\nWe recently considered how processes specific to action execution could provide information required to solve this problem\n(McDougle et al., 2016). We compared a traditional, buttonpressing \u201cbandit task\u201d with a modified version in which participants indicated their choices by reaching to one of two targets. In\nthe former, the absence of reward provided information about\nthe outcome probabilities associated with each stimulus (e.g.,\naction selection error), whereas in the latter, the absence of reward provided information about reaching inaccuracy (e.g., action execution error), indicated by a visual cursor that landed\noutside the target. The results showed that participants\u2019 choice\nbehavior was less sensitive to action execution errors compared\nwith action selection errors. We proposed that this difference\nmay have been due to the presence of a motor execution error\nsignal in the reaching condition.\nIn the motor domain, sensory prediction errors (SPEs), the\ndiscrepancy between the predicted and actual sensory feedback,\nare used to correct the ongoing movements or to drive motor\nadaptation (Wolpert et al., 1995; Tseng et al., 2007). This signal\ncould be directly exploited by the reinforcement learning system\nto solve the credit assignment problem. That is, the presence of an\nSPE could signal that the absence of the expected outcome (negative reward prediction error [RPE]) should be attributed to an\nerror in movement execution rather than an erroneous choice.\nThis \u201cbottom-up\u201d SPE hypothesis could provide a functional\naccount of the relatively direct connections between the cerebellum, a critical component in the generation of SPEs, and the basal\nganglia, parietal lobe, and orbital prefrontal cortex, core structures in reinforcement learning.\nAlternatively, the credit assignment problem could be solved\nby a more \u201ctop-down\u201d process related to a sense of agency, operationalized here as the belief that success or failure in obtaining\na reward is determined by motor performance rather than the\nresult of a property of the choices themselves. Green et al. (2010)\nproposed a model in which agency influences the rate of change\nin the values associated with response choices. In our reaching\nversion of the bandit task, this would result in behavior consistent\nwith discounting RPEs on trials with negative outcomes.\nThe current study further explores how action execution errors modulate reinforcement learning. The SPE hypothesis predicts that choice behavior should be sensitive to manipulations of\nthe strength of the SPE, even if those manipulations are irrelevant\nto the reward outcomes. In contrast, the agency hypothesis predicts that manipulations of SPE strength should have a minimal\neffect on biases in choice behavior, and instead be influenced by\nthe belief that the outcomes are dependent on their motor accuracy. Using a reaching variant of the two-armed-bandit task, we\nmanipulated SPE by delaying reach feedback (Experiment 1), and\nby using \u201cclamped\u201d reaching feedback (Experiment 2). In Experiment 2, we also manipulated the task instructions to test whether\nbiases in choice behavior were modulated by the participants\u2019\nsense of agency.\n\n",
    "methods": "\n_Participants._ All participants provided written consent, approved by the\ninstitutional review board at the University of California (Berkeley, CA).\nAll participants were right handed, based on self-report and an assessment with the Edinburgh Handedness Inventory (Oldfield, 1971). Participants received either class credit or monetary compensation.\n\n\nWacom, sampling rate \ufffd 200 Hz) while holding a digitizing pen, embedded in a custom handle. The stimuli were presented on a monitor that\nwas positioned above the tablet (53.2 cm \ufffd 30 cm, ASUS). The monitor\noccludedtheparticipant\u2019sviewoftheirhand. Theexperimentalsoftwarewas\n[custom written in MATLAB (The MathWorks) (RRID: SCR_001622) using](https://scicrunch.org/resolver/SCR_001622)\n[the Psychophysics toolbox extensions (Pelli, 1997) (RRID: SCR_002881).](https://scicrunch.org/resolver/SCR_002881)\n_Reaching task._ At the start of each trial, a white circle (diameter 1.2 cm)\nwas presented on the screen, indicating the start position (Fig. 1 _A_ ). The\nparticipant was instructed to move their hand to the start location. Feedback of hand position was indicated by a solid white circle (diameter 0.5\ncm). This feedback was only visible when the hand was within 2 cm of the\nstart position. After the cursor had been held in the start position for 1 s,\ntwo red circles (diameter 1 cm) were presented at a distance of 10 cm, at\n60\u00b0 and 120\u00b0 counter-clockwise relative to the right. The word \u201cGo\u201d\nappeared in the middle of the screen, instructing the participant to reach\nto one of the two circles. The participant was instructed to make a slicing\nmovement, attempting to pass through the selected target. Cursor feedback was removed once the movement was initiated. If the reach amplitude did not reach 10 cm within 1.5 s, the message \u201cPlease Reach Faster\u201d\nwas displayed and the trial was terminated. If the participant\u2019s reach\ndeviated too far from either target (angular error \ufffd20\u00b0), the message\n\u201cOut of Bounds\u201d was displayed. In both cases, the trial was immediately\nrepeated.\nIf the hand passed within 20\u00b0 of the target, one of two trial outcomes\noccurred. On rewarded trials, the target color changed to green, a pleasant \u201cding\u201d sound was played, and the number of points earned (1\u2013100)\nwas displayed above the chosen target. On unrewarded trials, the target\nremained red, an unpleasant \u201cbuzz\u201d sound was played, and the number\n\u201c0\u201d was displayed above the chosen target. A box on the top of the screen\nshowed the cumulative total of points earned.\n_Reward schedule._ To assess target choice preference independent of\nreaching accuracy, the reward schedules were predetermined; as such,\nthe outcomes were not contingent on whether or not the reaching movement actually intersected the selected target (with the exception of\nreaches judged to be out of bounds). Hit probability and reward functions were created using a bounded pseudo-sinusoidal function (Fig.\n1 _B_ ). These functions were mirrored for each target, such that the expected value for each target on a given trial was matched. For example, a\n\u201csafe\u201d target with a 90% hit probability and reward value of 10 points\nwould be paired with a matching risky target that had a 10% hit probability and rewarded 90 points. We operationally define risk in terms of\nthe probability of hitting the target. On hit trials, the participant received\nthe associated reward value for that trial; on miss trials, no points were\nawarded. The probability and reward functions were designed so that at\nmultiple points during the experiment, payoffs between the left and right\ntargets gradually shifted, allowing us to track the participant\u2019s choice\npreferences. The same reward schedule was used for all participants, with\nthe position of the targets counterbalanced.\n_Experiment 1._ Experiment 1 was designed to compare conditions in\nwhich reach errors were signaled by a strong or weak SPE ( _n_ \ufffd 20 per\ngroup; total _n_ \ufffd 60, 33 female, age range 18\u201325 years). At the location\nwhere the movement amplitude reached 10 cm, the cursor reappeared,\nproviding the participant with a feedback signal that indicated the accuracy of the reach (Fig. 1 _C_ ). Presuming that the participant had intended\nto hit the target, the difference between the center of the target and the\ncursor position indicated the SPE for that trial.\nGiven that the hit/miss outcomes were predetermined, it was necessary to alter the feedback on some of the trials. On trials where the reach\noutcome matched the predetermined outcome, the reach feedback was\nveridical: The feedback cursor would fall on the target on hit trials (22.5%\nof all trials) and off the target on miss trials (27.5% of all trials). On trials\nwhere the reach outcome and predetermined outcome did not match,\nthe reach feedback was manipulated. For \u201chits\u201d that had to be converted\nto \u201cmisses\u201d (25.5% of all trials), the cursor was displayed at a new location away from the target (in the same direction as the side of the target that\nwas hit). To mask the fact that the feedback was sometimes altered, the\ndistribution of the altered feedback signals was designed to closely match\n\n\n**Figure 1.** Experimental design. _**A**_, Trials began with participants moving their hand to place the cursor at the start position. They indicated their choice preference by performing a shooting\nmovement through the selected target. Visual feedback of the hand position was extinguished once the hand left the start position. In Experiment 1, visual feedback of the reach was provided on\nanimaginarycirclewitharadiusequaltothetargetdistance. Onhittrials,thetargetwouldturngreenandapleasant\u201cding\u201dsoundwasgenerated. Onmisstrials,thetargetwouldremainredand\nanunpleasant\u201cbuzz\u201dsoundwasgenerated. Thenumberofpointsearnedwasdisplayedabovethechosentarget(\u201c0\u201dinthecaseofamiss),alongwithacumulativetotalofpointsearneddisplayed\ninabox. _**B**_, Top, Rewardfunctions(leftaxis)andhitprobabilities(rightaxis)foreachtarget. Overtrials,thetargetsvaryintermsoftheirrelative\u201crisk\u201d(e.g.,highpayoffbutlowhitprobability)but\narealwaysmatchedintermsoftheexpectedpayoff. Bottom, Threegroupsweretestedwithdifferentfeedbackdelaysandintertrialintervals. ImmediateFeedbackandDelayedTrialsbothreceived\nimmediate reach feedback. Delayed Feedback received the same reach feedback but after a 2 s delay. _**C**_, Example feedback for hit and miss trials in Experiment 1. Veridical feedback was provided\nwhenparticipants\u2019actualaccuracy(hitormiss)matchedthepredeterminedoutcome. Fortrialswheretheydidnotmatch,thecursorwouldbebumpedinoroutofthetargetonthesameside,such\nthatparticipantswerenotawareoftheperturbation. _**D**_, InExperiment2,feedbackofreachingaccuracywasnotprovided. ForSPE\ufffd groups,onmisstrials,thefeedbackcursorwas\u201cclamped\u201dand\nalways presented at the same location between the two targets (regardless of which was chosen). On hit trials, no feedback cursor was presented. For SPE- groups, on all trials, no feedback cursor\nwas presented.\n\n\n**Figure 2.** Distribution of reach endpoints and feedback location. _**A**_, In Experiment 1, reach feedback was minimally altered to match the predetermined reward schedule. _**B**_, In Experiment 2,\nclampedfeedbackwasprovidedataninvariantlocation(90\u00b0)onmisstrialsfortheSPE [\ufffd] condition. Asaresult,theSPE [\ufffd] groupheadinganglesareshiftedawayfromthecenterrelativetotheSPE [\ufffd]\n\ngroup, due to implicit adaptation.\n\n\nfrom one side of a normal distribution with a SD of 4.65\u00b0, with the peak\ncentered on the edge of the target. Locations deviating further than 2\ntimesthedistribution\u2019sSD(9.3\u00b0)wereresampled. For\u201cmisses\u201dconvertedto\n\n\noriginal miss. We included the \u201cOut of Bounds\u201d criteria to ensure that the\nfeedback perturbations were relatively small, and thus prevent the participants from becoming aware of the feedback manipulation.\n\n\nprovided. Previous studies have demonstrated that delaying sensory\nfeedback by over 1 s can strongly attenuate the strength of an SPE (Held\net al., 1966; Kitazawa et al., 1995; Honda et al., 2012; Brudner et al., 2016;\nSchween and Hegele, 2017). In the Immediate Feedback group, the cursor reappeared as soon as the reach amplitude exceeded 10 cm (Fig. 1 _B_ ).\nIn the Delayed Feedback group, the cursor feedback was presented after\na 2 s delay. This manipulation confounds feedback delays and the time\nbetween successive trials. To unconfound these factors, we also tested a\nthird group who received immediate cursor feedback but then had to\nwait an additional 2 s before the start of the next trial (Delayed Trials).\n_Experiment 2._ In Experiment 2, we used a 2 \ufffd 2 factorial design ( _n_ \ufffd 20\nper group; total _n_ \ufffd 80, 51 female, age range 18\u201325 years). The first factor\nwas to test whether an explicit sense of agency would alter participants\u2019\nchoice behavior. The second was to provide a second test of the SPE\nhypothesis.\nIn our previous study, we found no effect of agency (McDougle et al.,\n2016); however, our manipulation, which involved instructing participants that they were either in control or not in control of the hit/miss\noutcomes, may have been complicated by the inclusion of reach feedback\nin the vicinity of the target. The reach feedback may have unintentionally\nswayed participants to believe that they were still in control, regardless of\nthe instructions. Here, we avoided this conflict by removing reach feedback completely. To manipulate a sense of agency, the participants were\ntold that miss trials were either related or not related to their reaching\naccuracy. In the former case, the participants were told that the trial\noutcome reflected whether their reach accurately intersected the chosen\ntarget (Agency [\ufffd] ). In the latter case, the participants were told that the\noutcome reflected a probability that a target choice would result in a\npayoff, independent of their reaching accuracy (Agency [\ufffd] ). Beyond this\ninstruction, the participants were not informed about the nature of the\nhit probabilities or reward schedule.\nWe also sought a second test of the SPE hypothesis, comparing conditions that did or did not include SPEs on miss trials. For participants in\nthe SPE [\ufffd] conditions, we used a variant of task irrelevant clamped feedback (Morehead et al., 2017; Kim et al., 2018) to elicit SPEs without\nconveying reaching performance: On miss trials, the cursor feedback was\nalways presented at a common location positioned between the two targets (90\u00b0) (Fig. 1 _D_ ), appearing as soon as the reach amplitude exceeded\n10 cm. The participants were fully informed that, regardless of which\ntarget was selected, the feedback would always appear straight ahead on\nunrewarded trials. Given the instructions and lack of spatial correlation\nbetween the feedback and reaching movement (Fig. 2 _B_ ), we assumed that\nthese participants would not confuse the clamped feedback as indicative\nof their reach angle. Nonetheless, based on our previous work with\nclamped feedback of this sort, we assumed that these conditions would be\nsufficient to elicit SPE-dependent adaptation and, indeed, confirmed this\nin a separate \u201cClamp-only\u201d control experiment (see \u201cClamp-only\u201d experiment below).\nParticipants in the SPE [\ufffd] conditions received clamped feedback on all\nmiss trials. This feedback signal was not presented to participants in the\nSPE [\ufffd] conditions. Neither group received cursor feedback on hit trials.\n_Experiment 2 block structure._ The experiment consisted of 30 baseline\ntrials, 400 decision making trials, and 30 aftereffect trials. The 400 decision making trials had the same reward schedule as Experiment 1. For the\nbaseline and aftereffect trials, only one of the two targets were presented\non each trial (location randomized), and the participant was instructed\nto reach to the target. A \u201cding\u201d indicated that the movement amplitude\nhad exceeded 10 cm. No information was provided concerning reaching\n\naccuracy.\nThe baseline and aftereffect trials were included to assess whether the\nclamped feedback was treated by the motor system as an SPE. If so, the\nheading direction in the aftereffect block should be shifted in the lateral\ndirection compared with the baseline block. Visuomotor adaptation was\noperationalized as a shift in heading angle in the aftereffect trials relative\nto baseline. The heading angle was defined as the angle between the hand\nposition when it crossed the target radius, the start position, and the\ntarget. The heading angle values for the 60\u00b0 target (to the right) were\n\n\ntion to the clamped feedback). All reported aftereffects were baseline\nsubtracted, where the baseline was defined as the mean of all baseline\ntrials.\n_Clamp-only experiment._ The design and logic of Experiment 2 rests on\nthe assumption that the clamped visual feedback is treated as an SPE\n(Morehead et al., 2017; Kim et al., 2018). Although the comparison of the\nbaseline and aftereffect blocks in Experiment 2 provides a test of this\nassumption, we thought it prudent to conduct a clamp-only experiment\nthat used a more traditional sensorimotor adaptation design, one in\nwhich the participants did not have to choose the reach target.\nReaches were made to a single target, displayed at either 60\u00b0 or 120\u00b0,\nthe locations used in Experiments 1 and 2 (see Fig. 4 _A_ ). The experiment\nconsisted of 30 baseline trials (15/target) in which no visual feedback was\nprovided, 120 \u201cclamp\u201d trials (60/target), and 10 aftereffect trials (5/target), again with no visual feedback. The trial structure was the same as in\nthe baseline and aftereffects blocks of Experiment 2.\nThe clamp-only experiment also provided an opportunity to test the\neffect of delayed visual feedback on sensorimotor adaptation, relevant to\nour manipulation in Experiment 1. Two groups were tested (14/group,\n14 female, age range 18\u201325 years), one in which the clamped feedback\nwas provided coincidentally with the reach endpoint (\u201cNo Delay\u201d), and a\nsecond in which the feedback was delayed by 2 s (\u201cDelay\u201d). If the clamp is\ntreated as an SPE, adaptation should be evident in the \u201cNo Delay\u201d group\nand abolished, or severely attenuated in the \u201cDelay\u201d group.\n_Statistical analysis._ The chosen sample sizes were based on our previous studies using the reaching variant of the two-armed bandit (McDougle et al., 2016) and the clamp method (Morehead et al., 2017; Kim et\nal., 2018). All _t_ tests were two-tailed and used a threshold for significance\n(\ufffd) of 0.05 unless stated otherwise. We computed the inverse Bayesfactor ( _BF_ 01) for our results from Experiment 1 to assess the likelihood of\nthe null hypothesis ( _H_ 0) relative to the SPE hypothesis ( _H_ 1). We used a\nmethod proposed by Rouder et al. (2009), using a prior for effect size\nfollowing a Cauchy distribution with a scale factor of 1. Here, _BF_ 01 \ufffd 1/3\ncan be considered as strong evidence in favor of the alternative hypothesis, _BF_ 01 \ufffd 3 as strong evidence in favor of the null hypothesis, and\nanything between is only considered weak or anecdotal (Dienes, 2014).\n\n",
    "results": "\n**Experiment 1**\nIn Experiment 1, we set out to test the SPE hypothesis, the idea\nthat the operation of the reinforcement learning system is attenuated following trials in which the absence of a reward is attributed to an error in action execution rather than action selection.\nThe core prediction of this bottom-up hypothesis is that the\nstrength of the SPE signal should influence choice behavior. Participants were tested in a two-armed bandit task, indicating their\nchoices on each trial by reaching to one of two targets. In addition\nto receiving reward feedback, cursor feedback indicated the accuracy of the reach. We compared two groups, an Immediate\nFeedback group who saw the feedback cursor immediately at the\nend of the reach; and a Delayed Feedback group, for whom the\nappearance of the feedback cursor was delayed by 2 s. Based on\nprevious studies, the strength, or salience of SPE should be considerably attenuated in the Delayed Feedback group (Held et al.,\n1966; Kitazawa et al., 1995; Honda et al., 2012; Brudner et al.,\n2016; Schween and Hegele, 2017). Given that the 2 s feedback\ndelay also increases the time between successive trials, we also\ntested a Delayed Trials group in which the feedback cursor appeared immediately at the end of the reach, but with an extra 2 s\npause between trials. In this manner, we matched the trial-to-trial\ninterval of the Delayed Feedback and Delayed Trials groups.\nIn standard bandit tasks in which the outcome is not dependentonactionexecution,peopletypicallyshowapreferenceforthe\n\u201csafe\u201d target, consistent with a risk aversion bias (Kahneman and\n\n\n**Figure3.** Increasingthetrial-to-trialinterval,eitherbydelayingfeedbackorincreasingtheintertrialintervalresultedinaweakerpreferencefortheriskytarget. _**A**_, Meangroupchoicebehavior\nreveals overall preference for riskier target throughout the experiment. Colored lines indicate the proportion of choices made to the riskier target, averaged over participants in each condition\n(calculatedovera19-trialwindowmovingaverage). Therelative\u201criskiness\u201doftarget1andtarget2(determinedbythepredefinedrewardschedule)areshownforillustrativepurposes(blacksolid\nanddashedlines). _**B**_, Riskpreferencequantifiedastheratiooftrialswheretheriskiertargetwaschosenoverthetotalnumberoftrials. Allgroupsexhibitedapreferencefortheriskierchoice(\ufffd0.50),\nwiththiseffectsignificantlygreaterfortheIFgroupcomparedwiththeothertwo. IF, ImmediateFeedback; DF, DelayedFeedback; DT, DelayedTrials. Errorbarsindicate \ufffd1SEMoverparticipants.\n\n\na striking reversal of this preference when the choices were indicated\nby reaches, so that the failure to obtain a reward was attributed to a\nfailure of action execution. The SPE hypothesis predicts that this\nreversal is due to the presence of SPEs on miss trials. Consistent with\nthose results, the Immediate Feedback group and Delayed Trials\ngroup showed a consistent preference for the riskier target over the\ncourse of the experiment (Fig. 3 _A_ ). However, in contrast to the SPE\nhypothesis,theDelayedFeedbackgroupalsoshowedareversalofthe\nrisk aversion bias, even though we assume the strength of the SPE is\ngreatly attenuated by the delay (an assumption we confirm in\nClamp-only Experiment).\nFor each trial, we defined the risky target as the one with the\nlower hit probability, but higher payoff and, as such, the option\nwith a larger variance of potential outcomes (Kahneman and\nTversky, 1979; Caraco et al., 1980; Dayan and Niv, 2008; Schultz,\n2016). Using this definition, we quantified participants\u2019 choice\nbiases by calculating the ratio of trials in which they picked the\nriskier target over the total number of trials (excluding the few\nout of bounds trials). A one-way ANOVA revealed a significant\neffect of group on risk bias ( _F_ (2,57) \ufffd 4.65, _p_ \ufffd 0.01; Fig. 3 _B_ ).\n_Post hoc t_ tests using Bonferroni-adjusted \ufffd levels of 0.017\n(.05/3) were conducted. A numerical but nonsignificant difference (after correcting for multiple comparisons) existed between\nthe Immediate Feedback and Delayed Feedback groups ( _t_ (38) \ufffd\n2.13, _p_ \ufffd 0.04). This difference is in a direction consistent with\nthe hypothesis that SPE influences choice behavior. However, we\nobserved a significant difference between the Immediate Feedback and Delayed Trials groups ( _t_ (38) \ufffd 2.95, _p_ \ufffd 0.005), indicating that an increase in intertrial interval alone (i.e., without\nmanipulating the SPE) affected choice preference. The Delayed\nFeedback group had a numerically lower risk bias compared with\nthe Delayed Trials group, opposite to what the SPE hypothesis predicts, although this difference was nonsignificant ( _t_ (38) \ufffd 0.93, _p_ \ufffd\n0.36). An inverse Bayes factor comparing the odds of the hypothesis\nthat the Delayed Feedback and Delayed Trials risk biases were equal\n(null) versus the hypothesis that they were unequal provided only\nweak support in favor of the null ( _BF_ 01 \ufffd 2.95).\nTogether, these results fail to support the hypothesis that\nchoice biases are modulated by the strength of the SPE. The most\nparsimonious interpretation of the current results is that choice\nbiases in the current task decay as a function of the time between\nsuccessive trials, independent of the strength of the SPE. This\n\n\nmemory that could be used to adjust the next movement (see\nDiscussion).\n\n\n**Experiment 2**\nThe results of the first experiment indicate that SPE is not a\ncritical signal that directly modulates choice biases. An alternative hypothesis is that, due to the sense of agency associated with\nreaching (Green et al., 2010), people may be slow to update their\nestimates of action execution errors based on recent outcomes.\nFor example, the participants have a strong prior for their reaching competency and believe that their execution errors simply\nreflect motor noise, a variable that should operate randomly\nacross trials. We set out to test this hypothesis in Experiment 2,\ncomparing conditions in which participants were told that the\nabsence of reward was attributed to a failure in motor execution\n(Agency [\ufffd] ) to conditions in which the absence of reward was\nattributed to a property of the object (Agency [\ufffd] ). If the sense of\nagency is critical, we would expect participants to prefer the\n\u201csafe\u201d target in the latter conditions.\nWe also designed Experiment 2 to provide a second test of the\nSPE hypothesis. To that end, we compared conditions in which\nthe trial outcome included clamped cursor feedback (SPE [\ufffd] ) or\ndid not include this feedback (SPE [\ufffd] ). This feedback, when provided, was always presented at the same location midway between\nthe two targets, independent of their target choice. Based on previous work with clamped feedback (Morehead et al., 2017; Kim et\nal., 2018), we assumed that this signal would automatically be\ntreated by the motor system as an SPE, driving sensorimotor\nadaptation. However, given the results of Experiment 1, we expected that the presence or absence of SPE would not influence\nchoice behavior.\nWe first verified that clamped feedback, even if only presented\nat the end of the movement, was sufficient to produce adaptation\n(see Materials and Methods, Clamp-Only Experiment). Despite\nbeing informed about the nature of the clamped feedback and\ninstructed to ignore it, robust adaptation was observed when the\nclamped feedback was presented: During the clamp block, the\nheading angle for each target shifted in the opposite direction of\nthe cursor and an aftereffect was observed (Fig. 4 _B_ ). A _t_ test of the\nbaseline-subtracted final heading angle revealed the aftereffect\nbeing significantly \ufffd0 ( _t_ (13) \ufffd 4.65, _p_ \ufffd 0.001). Moreover, these\neffects were absent if the feedback was delayed by 2 s ( _t_ (13) \ufffd\n\n\n**Figure 4.** Clamp-only experiment showing sensorimotor adaptation from clamped feedback, but only if the feedback is immediate. _**A**_, Participants were instructed to reach toward the single\ntarget. Clampedfeedbackwouldalwaysappearstraightaheadattheendofthereach,regardlessoftheparticipant\u2019sheadingangle. _**B**_, Immediateclampedfeedback(\u201cNoDelay\u201d)elicitsasignificant\naftereffectintheexpecteddirectionforbothtargets. Noaftereffectisobservedwhentheclampedfeedbackisdelayedby2s(\u201c2sDelay\u201d). Linesrepresentmeanheadingangleoverparticipantsand\nshaded regions around the lines represent \ufffd1 SEM over participants. Gray regions represent baseline and aftereffect trials with no feedback.\n\n\n**Figure5.** Senseofagency,butnotpresenceofSPE,influenceschoicepreference. _**A**_, Headingangleofreachesrevealsthetimecourseofadaptation. Headingangleforthe60\u00b0targetareflipped\nsuchthatpositiveisinthedirectionofadaptation. Linesindicatemeanheadingangleoverparticipants. Shadedregionsaroundthelinesrepresent \ufffd1SEMoverparticipants. Grayregionsrepresent\nbaselineandaftereffecttrialswhereonlyonetargetwaspresentedandnoreachfeedbackwasprovided. _**B**_, Baseline-subtractedaftereffectsshowsignificantadaptationforbothSPE [\ufffd] conditions,\nandnonefortheSPE [\ufffd] conditions. _**C**_, GroupaveragedchoicebehaviorshowsabiastowardthesafetargetfortheAgency [\ufffd] conditions,andnobiasforAgency [\ufffd] conditions. Coloredlinesindicate\ntheproportionofchoicesmadetotheriskiertarget,averagedoverparticipantsineachcondition(calculatedovera19-trialwindowmovingaverage). Therelative\u201criskiness\u201doftarget1andtarget\n2 (determined by the predefined reward schedule) are shown for illustrative purposes (black solid and dashed lines). _**D**_, Risk preference quantified as the ratio of trials where the riskier target was\nchosen over the total number of trials. Choice bias is influenced by a sense of agency, rather than SPE.\n\n\nrobust implicit learning (Held et al., 1966; Kitazawa et al., 1995;\nHonda et al., 2012; Brudner et al., 2016; Schween and Hegele,\n2017).\nAdaptation also occurred in response to the clamped feedback\nin the main experiment. During the choice trials, heading angle\nagain shifted in the opposite direction of the cursor (Fig. 5 _A_ ), and\nthere was a pronounced aftereffect (Fig. 5 _B_ ). (Such an accumulation of adaptation leading to an aftereffect would not occur\nin Experiment 1, as errors were presented on both sides for\neach target). These effects were not observed for the groups in\nwhich the cursor was never presented (SPE-groups). A two-way\nANOVA comparing the heading angle in the aftereffect block to\nthe baseline block revealed a main effect of SPE ( _F_ (1,76) \ufffd 40.7, _p_ \ufffd\n0.001), but no effect of agency ( _F_ (1,76) \ufffd 1.05, _p_ \ufffd 0.31) or an interaction ( _F_ (1,76) \ufffd 0.38, _p_ \ufffd 0.54). We note that the magnitude of\n\n\nindicate that adaptation is influenced by a sense of agency, the\nparticipants in the Agency [\ufffd] group chose the risky target more\noften (see below), experienced more \u201cmiss trials,\u201d and thus received more SPEs.\nHaving established that the clamped feedback was an effective\nSPE, we next asked whether choice behavior was influenced by\nthe presence of an SPE, a sense of agency, or an interaction of\nthese variables. When participants were led to believe that the\nabsence of reward was due to an action execution error, they did\nnot show the same risk averse (\u201csafe\u201d) bias compared with when\nthey were told that the absence of reward reflected a probabilistic\nproperty of the target. As can be seen in Figure 5 _C_, _D_, the\nAgency [\ufffd] groups tracked the \u201csafe\u201d target, whereas the Agency [\ufffd]\n\ngroups showed no consistent bias in their choice behavior. In\ncontrast, the presence of an SPE had no influence on choice be\n\n**Figure6.** AgencymodelfitsforExperiment2. _**A**_, Simulationsbasedonfittedparametersproducepatternofriskbiasesthataresimilar\ntothoseobservedinthefourconditionsofExperiment2. _**B**_, Fittedlearningparameters(\ufffdpayoff and \ufffdprob)foreachcondition. Agency [\ufffd]\n\nconditions have a lower \ufffdprob than Agency [\ufffd] conditions, consistent with the hypothesis that participants treat hit probabilities as less\ntemporallydependentwhentheyhaveasenseofagency. Errorbarsindicate \ufffd1SEMoverparticipants.\n\n\n_p_ \ufffd 0.78), and there was no interaction between these variables\n( _F_ (1,76) \ufffd 0.03, _p_ \ufffd 0.87).\nIn summary, the results of Experiment 2 indicate that the\npresence of SPE, although leading to adaptation, was not sufficient to influence decision making. In contrast, variation in the\nsense of agency did influence choice behavior, with participants\nmore likely to choose the risky target when they believed they\nwere in control, at least to some degree, of the trial outcome.\n\n\n**Model-based analysis of the agency hypothesis**\nExperiment 2 was designed to examine whether choice behavior\nis affected when a sense of agency is explicitly manipulated, operationalized as the belief that outcomes are the result of motor\nperformance. We hypothesized that a sense of agency would influence behavior by reducing the influence of temporal dependency of trial outcomes (Green et al., 2010). Specifically, if motor\nerrors are assumed to reflect random noise in the Agency [\ufffd] conditions, recent hits and misses would not be informative about\nfuture hits and misses. In contrast, hit and miss outcomes are\nindependent of the agent\u2019s motor accuracy in the Agency [\ufffd] conditions; thus, recent outcomes should provide useful information\nabout future outcomes.\nToevaluatewhetherthisagencyhypothesiscouldaccountforour\nobserved behavior in Experiment 2, we developed a reinforcement\nlearning model to capture how temporal dependency could influence choice behavior. In this model, the estimated hit probabilities\n_p\u02c6_ t( _x_ ) and payoffs _E_ t( _x_ ) for each target _x_ on trial _t_ are updated on a\ntrial-by-trial basis, based on the differences between the actual and\npredictedoutcomes(McDougleetal.,2016). Thedegreeoftemporal\ndependence is captured by two learning rate parameters, \ufffdprob and\n\ufffdpayoff, that correspond to the proportion that these estimates are\nupdated based on the previous trial outcome as follows:\n\n\n\ufffd _prob_, _t_ \ufffd _rt_ \ufffd _p\u02c6t_ \ufffd _x_ \ufffd\n\n\n\ufffd _payoff_, _t_ \ufffd _rt_ \ufffd _Et_ \ufffd _x_ \ufffd\n\n\n_p\u02c6t_ \ufffd1\ufffd _x_ \ufffd \ufffd _p\u02c6t_ \ufffd _x_ \ufffd \ufffd\ufffd _prob_ \ufffd _prob_, _t_\n# Et \ufffd1\ufffd x \ufffd \ufffd \ufffd EEt \ufffd t \ufffd xx \ufffd\ufffd, \ufffd\ufffd payoff \ufffd payoff, t, if missif hitt t\n\n\nwhere _p\u02c6_ t( _x_ ) takes on a value between 0 and\n1 for each target, representing the probability that a reach to that target will result\nin a hit. The hit or miss outcome (independent of reward), _r_ *, is coded as a 1 or 0\nfor a hit or a miss, respectively. Differences between the estimated hit probability and the actual outcome \ufffdprob,t, are\nmultiplied by \ufffdpayoff and added to the estimated hit probability for the next trial.\nAs a result, \ufffdprob captures the degree to\nwhich a participant updates the estimates\nof hit probability as a result of previous\ntrials. By fitting \ufffdprob as a free parameter\nfor each participant, we can estimate the\ndegree to which they behaved as though\nthey believed the hit outcomes were tem\n)foreachcondition. Agency [\ufffd]\n\nporally dependent, with higher values\nrepresenting stronger temporal dependence. If participants treat motor execution errors as temporally independent\nwhen they believe the outcomes are dependent on their reaching accuracy (Agency [\ufffd] groups), we\nshould observe lower \ufffdprob compared with when they believe the\noutcomes are not dependent on reaching accuracy (Agency [\ufffd]\n\ngroups).\nEstimated payoffs were updated in a similar manner to estimated probabilities. However, for payoffs, _r_ takes on values from\n1 to 100 according to the observed payoff, and the update only\noccurs following hit trials. This conditional is a central component of the model, as it effectively separates trials in which outcomes are due to motor errors from trials that result in standard\nRPEs. \ufffdpayoff is fit as a free parameter for each participant and also\nreflects the degree of temporal dependence in payoffs. Because\nthe payoff amounts were not dependent on hit accuracy, but\nrather a property of the target, we expected \ufffdpayoff to be approximately constant across all the experimental conditions.\nEstimated target values _V_ ( _x_ ) were transformed into probabilities using a standard softmax function. The inverse temperature\nparameter (\ufffd) for the softmax was fit with one common value\nfor all 80 participants in Experiment 2, resulting in 161 free\nparameters in total (one \ufffdprob and \ufffdpayoff per participant, and\none common \ufffd). Free parameter estimates were made using\nthe fmincon function in MATLAB, which minimized the negative log likelihood of the choices for the parameters. The\nlearning rates (\ufffdprob and \ufffdpayoff) were bounded between 0 and\n1, and the inverse temperature parameter (\ufffd) was bounded\nbetween 0.05 and 10.\nWe fit the learning parameters, then generated choice data to\nsimulate risk preferences. The agency model was capable of simulating the pattern of behavioral risk biases observed in Experiment 2 (Fig. 6 _A_ ). Consistent with the predictions of the agency\nhypothesis, the groups that were told their reaching accuracy did\nnot influence hit probability (Agency [\ufffd] groups) had a higher\n\ufffdprobability value than the groups that were told their reaching\naccuracy determined the hit outcomes (Agency [\ufffd] groups) (Fig.\n6 _B_ ). A two-way ANOVA revealed a significant effect of agency on\n\ufffdprob ( _F_ (1,76) \ufffd 7.85, _p_ \ufffd 0.01), no effect of SPE ( _F_ (1,76) \ufffd 1.82,\n_p_ \ufffd 0.18), and no interaction between the two ( _F_ (1,76) \ufffd 0.08, _p_ \ufffd\n0.78). Also consistent with the agency hypothesis, a two-way\nANOVArevealednosignificanteffectsofagencyon \ufffdpayoff ( _F_ (1,76) \ufffd\n\n\nThese results support the hypothesis that differences in\nchoice behavior across groups were mainly influenced by the\ndegree to which they treated hit probabilities as being temporally dependent, with a belief of agency leading to more temporal independence.\n\n",
    "discussion": "\nPeople are less sensitive to unrewarded outcomes when they are\nattributed to errors in action execution rather than action selection (McDougle et al., 2016). The main objective of this study was\nto evaluate different cues that could be used to solve this credit\nassignment problem. In earlier work, we had proposed a bottom-up\nhypothesis by which cerebellar-dependent SPEs were exploited\nby the reinforcement learning system, signaling the presence of\nan execution error (McDougle et al., 2016). By this model, SPEs\nprovide a salient signal that the trial outcome should be attributed to the agent (i.e., execution error), rather than the chosen\nobject (i.e., selection error). We tested this hypothesis in Experiment 1 by manipulating the strength of SPE and in Experiment 2\nby presenting movement-irrelevant SPEs. In both cases, the results failed to support the hypothesis that SPE played a critical\nrole in producing the observed bias in choice behavior. Instead,\nwe found that the sense of agency had a significant effect on\nchoice behavior, suggesting that the credit assignment problem\nmay be solved in a more indirect, top-down manner.\n\n\n**Salience of SPEs does not influence biases in choice behavior**\nThe strongest argument against the SPE hypothesis comes from\nExperiment 1. Here we compared conditions in which the feedback cursor was presented immediately at the end of the movement or after a 2 s delay. Previous work, as well as our clamp-only\ncontrol experiment, has shown that a 2 s feedback delay strongly\nattenuates sensorimotor adaptation (Held et al., 1966; Kitazawa\net al., 1995; Honda et al., 2012; Brudner et al., 2016; Schween and\nHegele, 2017), presumably because the delay weakens the SPE. If\nSPE directly modulates choice preferences, then we expect participants to become more sensitive to unrewarded outcomes\nwhen the feedback was delayed. Although this effect was observed, a similar pattern was elicited when the intertrial interval\nwas extended by 2 s, even if the cursor feedback was immediate.\nThus, the most parsimonious account of these results is that the\ntime between successive choices, rather than SPE, decreased sensitivity to unrewarded outcomes.\nWhy might an increase in the intertrial interval change choice\npreferences? One hypothesis is that some form of iconic motor\nmemory is strong when the interval is short (Adams and Dijkstra,\n1966; Posner and Konick, 1966; Laabs, 1973; Annett, 1995; Miyamoto et al., 2014), leading the participants to believe they can\ncorrect the execution error. However, we found no evidence that\nparticipants showed a stronger adjustment in reach trajectories in\nthe Immediate Feedback condition compared with when the\nfeedback or intertrial interval was extended: The mean proportion of the error corrected on trials where feedback was artificially\nperturbed was 0.57 (SE \ufffd 0.04) for the Immediate Feedback\ncondition, 0.57 (0.08) for the Delayed Feedback condition, and\n0.53 (0.04) for the Delayed Trials conditions. A one-way ANOVA\non the regression between error and change in heading angle\nrevealed no effect of group ( _F_ (2,57) \ufffd 0.12, _p_ \ufffd 0.89). An alternative hypothesis is that the longer intertrial interval resulted in\nmore time discounting of the potential rewards for each target\n\n\nThe results of Experiment 2 provide further evidence against\nthe SPE hypothesis. Here we used a method in which the SPE\nsignal is not contingent on movement accuracy. Consistent with\nour previous work, this method was sufficient to produce adaptation in the reaching behavior of the participants. Nonetheless,\nchoice biases were similar, regardless of whether this signal was\npresent. Together, the results argue against a simple, bottom-up\nmodel in which an SPE signal is sufficient to attenuate value\nupdates when the outcome error is attributed to a failure in motor execution.\n\n\n**Choice biases are influenced by a sense of agency**\nThe results of the present study point toward a more top-down\nmechanism for solving the credit assignment required to differentiate execution and selection errors. This was most clearly\nobserved in the results of Experiment 2, where sensitivity to\nunrewarded outcomes was reduced when the instructions emphasized that the participants had some degree of agency in determining the outcome, with agency operationalized as the belief\nthat outcomes are dependent on one\u2019s motor performance. Similarly, Green et al. (2010) found that choice behavior could be\ndramatically altered by instructing participants that the trial outcome was either determined by the computer or contingent on\nmovement execution. Computationally, they suggested that people assume weaker temporal dependence between successive\nevents when the outcomes depend on motor output, given that\nerrors from motor noise are assumed to be random. Properties of\nthe object, however, may be more temporally dependent (e.g., the\ntarget with the high payoff on the previous trial is likely to yield a\nhigh payoff on the next trial).\nIn modeling the data from Experiment 2, we adopted an operational definition of agency introduced by Green et al. (2010),\nnamely, that a sense of agency will cause choices to be more\ntemporally independent. Consistent with the agency hypothesis,\nthe fits showed that participants in conditions of high agency\nwere less likely to behave as though hit outcomes were temporally\ndependent. In other words, by treating execution errors as\nthough they were random events and unlikely to occur again,\nthey were more likely to choose the target with the higher expected payoff. Participants in the low agency condition, however,\nwere more likely to behave as though misses were a property of\nthe target and, therefore, were biased to avoid the target which\nresulted in more misses.\nWe note that, in our earlier study (McDougle et al., 2016), we\nhad included a similar manipulation of a sense of control, informing participants that the position of the feedback cursor was\neither dependent or independent of their movement. Contrary to\nthe current results, we observed no effect of agency on choice\nbehavior when an SPE-like signal was present. However, the feedback cursor still appeared near the selected target, either as veridical feedback or in a slightly shifted position. It is possible that,\ndespite the instructions, the correlation between their movements and sensory feedback may have led the participants to\nbelieve, implicitly or explicitly, that they could control the reward\noutcomes. The clamped feedback used in Experiment 2 avoids\nthis problem because the feedback was spatially independent of\nthe movement.\nA similar explanation may also account for the betweenexperiment differences in choice behavior observed in conditions\nin which the participants were instructed to believe they were in\ncontrol of the trial outcomes. Although the reward schedules\n\n\nThis was verified in a _post hoc_ analysis, restricted to the Immediate\nFeedback condition in Experiment 1 and the two Agency [\ufffd]\n\ngroups in Experiment 2 ( _t_ (58) \ufffd 4.25, _p_ \ufffd 0.001). The main difference between these conditions was that endpoint reach feedback was provided in Experiment 1, but not Experiment 2. The\nendpoint feedback not only provided a salient cue for motor\nperformance, but also signaled a strong causal relationship association between trials in which the cursor hit the target and the\nparticipant being awarded points. These signals would likely increase the participants\u2019 confidence that the outcomes reflect their\nmotor performance, increasing their sense of agency and, thus,\nproduce a stronger risk bias.\nIn addition to an overall sense of agency, there is another way\nin which reach feedback might influence choice behavior. The\npresence of reach feedback results in salient, \u201cnear miss\u201d trials.\nThese have been shown, at least under some conditions, to produce similar hemodynamic responses as are observed with rewarded trials (Clark et al., 2009). Treating these near miss\noutcomes as rewarding, even if only slightly, would result in a\nstronger risk bias when reach feedback was present in Experiment\n1, but not in Experiment 2.\n\n\n**Mechanistic considerations for the modulation of**\n**reinforcement learning by execution errors**\nAs noted in the Introduction, distinguishing between action execution and action selection errors is important to optimize\nchoice behavior. Knocking over a cup of coffee should not make\nus dislike coffee, even though we failed to obtain an expected\nreward. Current models of decision making tend to be based on\ntasks in which execution errors are absent; yet these systems\nevolved in organisms in which outcomes almost always reflected\nthe interaction of processes involved in selection and execution.\nWe can envision two ways in which an execution error might gate\nvalue updating. The negative RPE signals associated with unsuccessful outcomes might be attenuated. Or the operation by which\nthese signals modify value representations might be disrupted.\nThe SPE hypothesis was motivated, in part, by consideration\nof recently described projections between the cerebellum and\nbasal ganglia (Hoshi et al., 2005; Bostan et al., 2010; Chen et al.,\n2014) and association areas of the cerebral cortex implicated in\nvalue representation (O\u2019Doherty, 2004; Choi et al., 2012). We\nhypothesized that execution error signals, which evolved to keep\nthe sensorimotor system calibrated, may have come to be exploited by the reinforcement learning system. However, the results from the current experiments provide strong evidence\nagainst this simple, bottom-up account of how a decision-making\nsystemmightdistinguishbetweenactionexecutionandactionselection errors.\nInstead, the current results suggest that this gating process is\ndriven by explicit knowledge about the source of errors, information that is dependent on a sense of agency. This contextual\nknowledge could have a direct influence on how RPEs are computed or used to update value representations. The recruitment\nof working memory (Collins et al., 2017) and explicit knowledge\nabout task contingencies (Li et al., 2011) have been shown to\naffect hemodynamic signatures of RPEs in ventral striatum and\nventromedial prefrontal cortex. In a similar fashion, top-down\nknowledge about the success or failure of action execution could\nprovide a similar modulatory signal, either to a system generating\nRPEs or using this information to update value representations.\n\n\nsensitive to the intersection of action execution and action\n\nselection.\n\n",
    "references": "Adams JA, Dijkstra S (1966) Short-term memory for motor responses. J Exp\n[Psychol 71:314\u2013318. CrossRef Medline](http://dx.doi.org/10.1037/h0022846)\nAnnett J (1995) Motor imagery: perception or action? Neuropsychologia\n[33:1395\u20131417. CrossRef Medline](http://dx.doi.org/10.1016/0028-3932(95)00072-B)\nBostan AC, Dum RP, Strick PL (2010) The basal ganglia communicate with\n[the cerebellum. Proc Natl Acad Sci U S A 107:8452\u20138456. CrossRef](http://dx.doi.org/10.1073/pnas.1000496107)\n\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/20404184)\nBrudner SN, Kethidi N, Graeupner D, Ivry RB, Taylor JA (2016) Delayed\nfeedback during sensorimotor learning selectively disrupts adaptation but\n[not strategy use. J Neurophysiol 115:1499\u20131511. CrossRef Medline](http://dx.doi.org/10.1152/jn.00066.2015)\nCaraco T, Martindale S, Whittam TS (1980) An empirical demonstration of\n[risk-sensitive foraging preferences. Anim Behav 28:820\u2013830. CrossRef](http://dx.doi.org/10.1016/S0003-3472(80)80142-4)\nChen CH, Fremont R, Arteaga-Bracho EE, Khodakhah K (2014) Short latency cerebellar modulation of the basal ganglia. Nat Neurosci 17:1767\u2013\n[1775. CrossRef Medline](http://dx.doi.org/10.1038/nn.3868)\nChoi EY, Yeo BT, Buckner RL (2012) The organization of the human striatum estimated by intrinsic functional connectivity. J Neurophysiol 108:\n[2242\u20132263. CrossRef Medline](http://dx.doi.org/10.1152/jn.00270.2012)\nClark L, Lawrence AJ, Astley-Jones F, Gray N (2009) Gambling near-misses\nenhance motivation to gamble and recruit win-related brain circuitry.\n[Neuron 61:481\u2013490. CrossRef Medline](http://dx.doi.org/10.1016/j.neuron.2008.12.031)\nCollins AG, Ciullo B, Frank MJ, Badre D (2017) Working memory load\n[strengthens reward prediction errors. J Neurosci 37:4332\u20134342. CrossRef](http://dx.doi.org/10.1523/JNEUROSCI.2700-16.2017)\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/28320846)\nDayan P, Niv Y (2008) Reinforcement learning: the good, the bad and the\n[ugly. Curr Opin Neurobiol 18:185\u2013196. CrossRef Medline](http://dx.doi.org/10.1016/j.conb.2008.08.003)\nDienes Z (2014) Using Bayes to get the most out of non-significant results.\n[Front Psychol 5:781. CrossRef Medline](http://dx.doi.org/10.3389/fpsyg.2014.00781)\nFrederick S, Loewenstein G, O\u2019Donoghue T (2002) Time discounting and\n[time preference: a critical review. J Econ Lit 40:351\u2013401. CrossRef](http://dx.doi.org/10.1257/jel.40.2.351)\nGreen CS, Benson C, Kersten D, Schrater P (2010) Alterations in choice\nbehavior by manipulations of world model. Proc Natl Acad Sci U S A\n[107:16401\u201316406. CrossRef Medline](http://dx.doi.org/10.1073/pnas.1001709107)\nHartmann MN, Hager OM, Tobler PN, Kaiser S (2013) Parabolic discounting of monetary rewards by physical effort. Behav Processes 100:192\u2013196.\n[CrossRef Medline](http://dx.doi.org/10.1016/j.beproc.2013.09.014)\nHeld R, Efstathiou A, Greene M (1966) Adaptation to displaced and delayed\nvisual feedback from the hand. J Exp Psychol 72:887\u2013891.\nHonda T, Hirashima M, Nozaki D (2012) Habituation to feedback delay\nrestores degraded visuomotor adaptation by altering both sensory prediction error and the sensitivity of adaptation to the error. Front Psychol\n[3:540. CrossRef Medline](http://dx.doi.org/10.3389/fpsyg.2012.00540)\nHoshi E, Tremblay L, Fe\u00b4ger J, Carras PL, Strick PL (2005) The cerebellum\n[communicates with the basal ganglia. Nat Neurosci 8:1491\u20131493. CrossRef](http://dx.doi.org/10.1038/nn1544)\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/16205719)\nKahneman D, Tversky A (1979) Prospect theory: an analysis of decision\n[under risk. Econometrica 47:263\u2013291. CrossRef](http://dx.doi.org/10.2307/1914185)\nKim HE, Morehead JR, Parvin DE, Moazzezi R, Ivry RB (2018) Invariant\nerrors reveal limitations in motor correction rather than constraints on\n[error sensitivity. Commun Biol 1:19. CrossRef](http://dx.doi.org/10.1038/s42003-018-0021-y)\nKitazawa S, Kohno T, Uka T (1995) Effects of delayed visual information on\nthe rate and amount of prism adaptation in the human. J Neurosci 15:\n[7644\u20137652. CrossRef Medline](http://dx.doi.org/10.1523/JNEUROSCI.15-11-07644.1995)\nLaabs GJ (1973) Retention characteristics of different reproduction cues in\n[motor short-term memory. J Exp Psychol 100:168\u2013177. CrossRef](http://dx.doi.org/10.1037/h0035502)\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/4744492)\nLandy MS, Trommersha\u00a8user J, Daw ND (2012) Dynamic estimation of\ntask-relevant variance in movement under risk. J Neurosci 32:12702\u2013\n[12711. CrossRef Medline](http://dx.doi.org/10.1523/JNEUROSCI.6160-11.2012)\nLi J, Delgado MR, Phelps EA (2011) How instructed knowledge modulates\nthe neural systems of reward learning. Proc Natl Acad Sci U S A 108:55\u2013\n[60. CrossRef Medline](http://dx.doi.org/10.1073/pnas.1014938108)\nMcDougle SD, Boggess MJ, Crossley MJ, Parvin D, Ivry RB, Taylor JA (2016)\nCredit assignment in movement-dependent reinforcement learning. Proc\n[Natl Acad Sci U S A 113:6797\u20136802. CrossRef Medline](http://dx.doi.org/10.1073/pnas.1523669113)\nMiyamoto YR, Wang SX, Brennan AE, Smith MA (2014) Distinct forms of\n\n\ntional and Computational Motor Control, Washington DC, District of\nColumbia.\n\nMorehead JR, Taylor JA, Parvin DE, Ivry RB (2017) Characteristics of implicit sensorimotor adaptation revealed by task-irrelevant clamped feed[back. J Cogn Neurosci 29:1061\u20131074. CrossRef Medline](http://dx.doi.org/10.1162/jocn_a_01108)\nNiv Y, Edlund JA, Dayan P, O\u2019Doherty JP (2012) Neural prediction errors\nreveal a risk-sensitive reinforcement-learning process in the human\n[brain. J Neurosci 32:551\u2013562. CrossRef Medline](http://dx.doi.org/10.1523/JNEUROSCI.5498-10.2012)\nO\u2019Doherty JP (2004) Reward representations and reward-related learning\nin the human brain: insights from neuroimaging. Curr Opin Neurobiol\n[14:769\u2013776. CrossRef Medline](http://dx.doi.org/10.1016/j.conb.2004.10.016)\n\nOldfield RC (1971) The assessment and analysis of handedness: the Edin[burgh Inventory. Neuropsychologia 9:97\u2013113. CrossRef Medline](http://dx.doi.org/10.1016/0028-3932(71)90067-4)\nPelli DG (1997) The VideoToolbox software for visual psychophysics:\n[transforming numbers into movies. Spat Vis 10:437\u2013442. CrossRef](http://dx.doi.org/10.1163/156856897X00366)\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/9176953)\n\nPosner MI, Konick AF (1966) Short-term retention of visual and kinesthetic\n[information. Organ Behav Hum Perform 1:71\u201386. CrossRef](http://dx.doi.org/10.1016/0030-5073(66)90006-7)\nRescorla RA, Wagner AR (1972) A theory of Pavlovian conditioning: variations in the effectiveness of reinforcement and nonreinforcement. In:\n\nClassical conditioning, Vol II: Current research and theory (Black AH,\nProkasy WF, eds), pp 64\u201399. New York, NY: Appleton-Century-Crofts.\nRouder JN, Speckman PL, Sun D, Morey RD, Iverson G (2009) Bayesian _t_\ntests for accepting and rejecting the null hypothesis. Psychon Bull Rev\n[16:225\u2013237. CrossRef Medline](http://dx.doi.org/10.3758/PBR.16.2.225)\n\n\nSchultz W (2016) Dopamine reward prediction error coding. Dialogues\n[Clin Neurosci 18:23\u201332. Medline](http://www.ncbi.nlm.nih.gov/pubmed/27069377)\nSchultz W, Dayan P, Montague PR (1997) A neural substrate of prediction\n[and reward. Science 275:1593\u20131599. CrossRef Medline](http://dx.doi.org/10.1126/science.275.5306.1593)\nSchween R, Hegele M (2017) Feedback delay attenuates implicit but facilitates explicit adjustments to a visuomotor rotation. Neurobiol Learn\n[Mem 140:124\u2013133. CrossRef Medline](http://dx.doi.org/10.1016/j.nlm.2017.02.015)\nTrommersha\u00a8user J, Maloney LT, Landy MS (2008) Decision making, movement planning, and statistical decision theory. Trends Cogn Sci 12:291\u2013\n[297. CrossRef Medline](http://dx.doi.org/10.1016/j.tics.2008.04.010)\nTseng YW, Diedrichsen J, Krakauer JW, Shadmehr R, Bastian AJ (2007)\nSensory prediction errors drive cerebellum-dependent adaptation of\n[reaching. J Neurophysiol 98:54\u201362. CrossRef Medline](http://dx.doi.org/10.1152/jn.00266.2007)\nWalton ME, Kennerley SW, Bannerman DM, Phillips PE, Rushworth MF\n(2006) Weighing up the benefits of work: behavioral and neural analyses\n[of effort-related decision making. Neural Netw 19:1302\u20131314. CrossRef](http://dx.doi.org/10.1016/j.neunet.2006.03.005)\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/16949252)\nWolpert DM, Ghahramani Z, Jordan MI (1995) An internal model for sen[sorimotor integration. Science 269:1880\u20131882. CrossRef Medline](http://dx.doi.org/10.1126/science.7569931)\nWu SW, Delgado MR, Maloney LT (2009) Economic decision-making\ncompared with an equivalent motor task. Proc Natl Acad Sci U S A 106:\n[6088\u20136093. CrossRef Medline](http://dx.doi.org/10.1073/pnas.0900102106)\nWu SW, Delgado MR, Maloney LT (2011) The neural correlates of subjective utility of monetary outcome and probability weight in economic and\n[in motor decision under risk. J Neurosci 31:8822\u20138831. CrossRef](http://dx.doi.org/10.1523/JNEUROSCI.0540-11.2011)\n[Medline](http://www.ncbi.nlm.nih.gov/pubmed/21677166)\n\n\n"
  },
  "tables": [],
  "page_count": 10,
  "metadata": {
    "title": "Credit Assignment in a Motor Decision Making Task Is Influenced by Agency and Not Sensory Prediction Errors",
    "author": "",
    "subject": "",
    "creator": "XPP"
  },
  "extraction_method": "pymupdf4llm",
  "char_count": 59845,
  "word_count": 8576,
  "is_multi_column": true
}